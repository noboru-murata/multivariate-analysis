#+TITLE: 判別分析 
#+SUBTITLE: 分析の評価
#+AUTHOR: 村田 昇
#+EMAIL: noboru.murata@eb.waseda.ac.jp
#+DATE: 
# Time-stamp: <2022-11-24 13:25:35 mura>
:REVEAL:
#+INCLUDE: "./reveal.js/org/mycourse.org"
#+PROPERTY: header-args:R :cache yes :session *R*
# #+PROPERTY: header-args:R+ :exports both :results output
#+PROPERTY: header-args:R+ :width 800 :height 800 :res 100
#+PROPERTY: header-args:R+ :tangle no
#+PROPERTY: header-args:latex :exports results :results raw
#+STARTUP: hidestars content indent
#+STARTUP: hidestars content indent
# C-c C-x C-v でinlineを切り替え
# <m C-i でlatex block (math env用)
# C-c '
:END:

* COMMENT メモ
- 第3講以降は同じファイルを使うように整理する
- 同じタイトルの項目にはメモを入れる
- 演習の内容が異なるので演習は2つ作る形で対応

* COMMENT 講義の内容
# 早稲田大学
- 第1日 : 判別分析の考え方
- *第2日 : 分析の評価*

#+begin_src R :eval no :exports none :tangle yes
  ### 第9講 資料
#+end_src
#+begin_src R :exports none
  setwd("~/Desktop/lectures/mva/slide")
#+end_src

* COMMENT 講義概要
# 東京大学
- 第1日 : 判別分析の考え方
- *第2日 : 分析の評価*

#+begin_src R :eval no :exports none :tangle yes
  ### 
  ### 第9講 サンプルコード
  ###
#+end_src
#+begin_src R :exports none
  setwd("~/Desktop/lectures/u-tokyo/autumn/slide")
#+end_src

* COMMENT 演習 (早稲田大学雛型)
:PROPERTIES:
:reveal_background: #fef4f4
:END:
# 早稲田大学
** 問題
:PROPERTIES:
:reveal_background: #fef4f4
:END:
- について以下を示しなさい．
  - である．
    #+begin_quote
    #+begin_src latex
    #+end_src
    #+end_quote

** 解答例
:PROPERTIES:
:reveal_background: #fef4f4
:END:
- いずれも定義にもとづいて計算すればよい
  #+begin_quote
  #+begin_src latex
  #+end_src
  #+end_quote

* COMMENT 演習 (東京大学雛型)
:PROPERTIES:
:reveal_background: #fef4f4
:END:
# 東京大学
** R : 概要
:PROPERTIES:
:reveal_background: #fef4f4
:END:
- ほげほげな方法:
  #+begin_src R :eval no
  #+end_src
  
** データセット
:PROPERTIES:
:reveal_background: #fef4f4
:END:
- 以下のデータセットを使用します
  - ~xxx~
    #+begin_quote
    データの素性
    #+end_quote
    [[https://www.foo.com/]]

** 練習問題
:PROPERTIES:
:reveal_background: #fef4f4
:END:
- 構成しなさい
  - データ
    #+begin_quote
    formulaなどを与える
    #+end_quote

#+begin_src R :eval no :exports none :tangle yes
  ###
  ### 練習問題 
  ###

  ## 
  ## 分析
  ##
#+end_src

** COMMENT 講義資料: 概略
:PROPERTIES:
:reveal_background: #EEEEFF
:END:
- [[./code/bar.r][bar.r]] を確認してみよう


* 判別分析の復習
** 判別分析
- 個体の特徴量から
  その個体の属するクラスを予測する関係式を構成
- *事前確率* : \(\pi_k=P(Y=k)\) (prior probability)
  - \(X=\boldsymbol{x}\) が与えられる前に予測されるクラス
- *事後確率* : \(p_k(\boldsymbol{x})\) (posterior probability)
  - \(X=\boldsymbol{x}\) が与えられた後に予測されるクラス
    #+begin_quote
    #+begin_src latex
      \begin{equation}
        p_k(\boldsymbol{x})=P(Y=k|X=\boldsymbol{x})
      \end{equation}
    #+end_src
    #+end_quote
  - 所属する確率が最も高いクラスに個体を分類

** 判別関数
- 判別の手続き
  - 説明変数 \(X=\boldsymbol{x}\) の取得
  - 事後確率 \(p_k(\boldsymbol{x})\) の計算
  - 事後確率最大のクラスにデータを分類
- *判別関数* : \(\delta_k(\boldsymbol{x})\) (\(k=1,\dots,K\))
  #+begin_quote
  #+begin_src latex
    \begin{equation}
      p_k(\boldsymbol{x}) 
      < 
      p_l(\boldsymbol{x})
      \Leftrightarrow
      \delta_k(\boldsymbol{x})
      <
      \delta_l(\boldsymbol{x})
    \end{equation}
  #+end_src
  #+end_quote
  事後確率の順序を保存する計算しやすい関数
- 判別関数 \(\delta_k(\boldsymbol{x})\) を最大化するようなクラス \(k\) に分類

** 線形判別
- \(f_k(\boldsymbol{x})\) の仮定
  - \(q\) 変量正規分布の密度関数
  - 平均ベクトル \(\boldsymbol{\mu}_k\) : クラスごとに異なる
  - 共分散行列 \(\Sigma\) : *すべてのクラスで共通*
    #+begin_quote
    #+begin_src latex
      \begin{equation}
	f_k(\boldsymbol{x})
	=
	\frac{1}{(2\pi)^{q/2}\sqrt{\det\Sigma}}
	\exp\left(-\frac{1}{2}(\boldsymbol{x}-\boldsymbol{\mu}_k)^{\mathsf{T}}
	  \Sigma^{-1}(\boldsymbol{x}-\boldsymbol{\mu}_k)\right)
      \end{equation}
    #+end_src
    #+end_quote
- 線形判別関数 : \(\boldsymbol{x}\) の1次式
  # (linear discriminant function)
  #+begin_quote
  #+begin_src latex
    \begin{equation}
      \delta_k(\boldsymbol{x})
      =
      \boldsymbol{x}^{\mathsf{T}}\Sigma^{-1}\boldsymbol{\mu}_k
      -\frac{1}{2}\boldsymbol{\mu}_k^{\mathsf{T}}\Sigma^{-1}\boldsymbol{\mu}_k
      +\log\pi_k
    \end{equation}
  #+end_src
  #+end_quote

** 2次判別
- \(f_k(\boldsymbol{x})\) の仮定
  - \(q\) 変量正規分布の密度関数
  - 平均ベクトル \(\boldsymbol{\mu}_k\) : クラスごとに異なる
  - 共分散行列 \(\Sigma_k\) : *クラスごとに異なる*
    #+begin_quote
    #+begin_src latex
      \begin{equation}
	f_k(\boldsymbol{x})
	=
	\frac{1}{(2\pi)^{q/2}\sqrt{\det\Sigma_k}}
	\exp\left(-\frac{1}{2}(\boldsymbol{x}-\boldsymbol{\mu}_k)^{\mathsf{T}}
	  \Sigma_k^{-1}(\boldsymbol{x}-\boldsymbol{\mu}_k)\right)
      \end{equation}
    #+end_src
    #+end_quote
- 2次判別関数 : \(\boldsymbol{x}\) の2次式
  #+begin_quote
  #+begin_src latex
    \begin{equation}
      \delta_k(\boldsymbol{x})
      =
      -\frac{1}{2}\det\Sigma_k
      -\frac{1}{2}(\boldsymbol{x}-\boldsymbol{\mu}_k)^{\mathsf{T}}
      \Sigma_k^{-1}(\boldsymbol{x}-\boldsymbol{\mu}_k)
      +\log\pi_k
    \end{equation}
  #+end_src
  #+end_quote

** Fisherの線形判別
- 新しい特徴量 \(Z=\boldsymbol{\alpha}^{\mathsf{T}} X\) を考える
- 良い \(Z\) の基準
  - クラス内では集まっているほど良い (\(\boldsymbol{\alpha}^{\mathsf{T}} W\boldsymbol{\alpha}\)は小)
  - クラス間では離れているほど良い (\(\boldsymbol{\alpha}^{\mathsf{T}} B\boldsymbol{\alpha}\)は大)
- Fisherの基準
  #+begin_quote
  #+begin_src latex
    \begin{equation}
      \text{maximize}\quad \boldsymbol{\alpha}^{\mathsf{T}} B\boldsymbol{\alpha}
      \quad\text{s.t.}\quad \boldsymbol{\alpha}^{\mathsf{T}} W\boldsymbol{\alpha}=\text{const.}
    \end{equation}
  #+end_src
  #+end_quote
  - \(\boldsymbol{\alpha}\) は \(W^{-1}B\) の第1から第 \(K-1\) 固有ベクトル
  - 判別方法: 特徴量の距離を用いる
  - \(d_{k}=\sum_{l=1}^{K-1}(\alpha_l^{\mathsf{T}}\boldsymbol{x}-\alpha_l^{\mathsf{T}}\mu_k)^2\) 
		が最小のとなるクラス \(k\) に判別


* 2値判別分析の評価
** 誤り率
- 単純な誤り
  #+begin_quote
  #+begin_src latex
    \begin{equation}
      \text{(誤り率)}
      =\frac{\text{(誤って判別されたデータ数)}}
      {\text{(全データ数)}}
    \end{equation}
  #+end_src
  #+end_quote
- 判別したいラベル : 陽性 (positive)
  - *真陽性* : 正しく陽性と判定 (true positive; TP)
  - *偽陽性* : 誤って陽性と判定 (false positive; FP) (*第I種過誤*)
  - *偽陰性* : 誤って陰性と判定 (false negative; FN) (*第II種過誤*)
  - *真陰性* : 正しく陰性と判定 (true negative; TN) 

** 混同行列
|------------+-------------------------+-------------------------|
|            | 真値は陽性              | 真値は陰性              |
|------------+-------------------------+-------------------------|
| 判別は陽性 | 真陽性 (True Positive)  | 偽陽性 (False Positive) |
| 判別は陰性 | 偽陰性 (False Negative) | 真陰性 (True Negative)  |
|------------+-------------------------+-------------------------|
- *confusion matrix*
- 転置で書く流儀もあるので注意

** 混同行列
|------------+-------------------------+-------------------------|
|            | 判別は陽性              | 判別は陰性              |
|------------+-------------------------+-------------------------|
| 真値は陽性 | 真陽性 (True Positive)  | 偽陰性 (False Negative) |
| 真値は陰性 | 偽陽性 (False Positive) | 真陰性 (True Negative)  |
|------------+-------------------------+-------------------------|
- パターン認識や機械学習で多く見られた書き方
- 誤差行列 (error matrix) とも呼ばれる

** 基本的な評価基準
- 定義
  #+begin_quote
  #+begin_src latex
    \begin{align}
      \text{(真陽性率)}
      &=\frac{TP}{TP+FN} \qquad\text{(true positive rate)}\\
      \text{(真陰性率)}
      &=\frac{TN}{FP+TN} \qquad\text{(true negative rate)}\\
      \text{(適合率)}
      &=\frac{TP}{TP+FP} \qquad\text{(precision)}\\
      \text{(正答率)}
      &=\frac{TP+TN}{TP+FP+TN+FN} \qquad\text{(accuracy)}
    \end{align}
  #+end_src
  #+end_quote

#+reveal: split
- 別名 (分野で異なるので注意)
  - 感度 (sensitivity) あるいは 再現率 (recall)
    #+begin_quote
    #+begin_src latex
      \begin{equation}
	\text{(真陽性率)}
	=\frac{TP}{TP+FN}
      \end{equation}
    #+end_src
    #+end_quote
  - 特異度 (specificity)
    #+begin_quote
    #+begin_src latex
      \begin{equation}
	\text{(真陰性率)}
	=\frac{TN}{FP+TN}
      \end{equation}
    #+end_src
    #+end_quote
  - 精度
    #+begin_quote
    #+begin_src latex
      \begin{equation}
	\text{(正答率)}
	=\frac{TP+TN}{TP+FP+TN+FN}
      \end{equation}
    #+end_src
    #+end_quote

** F-値
- *F-measure, F-score*
- 定義
  #+begin_quote
  #+begin_src latex
    \begin{align}
      F_{1}&=\frac{2}{{1}/{\text{(再現率)}}+{1}/{\text{(適合率)}}}\\
      F_{\beta}&=\frac{\beta^{2}+1}{{\beta^{2}}/{\text{(再現率)}}+{1}/{\text{(適合率)}}}
    \end{align}
  #+end_src
  #+end_quote
  - 再現率(真陽性率)と適合率の(重み付き)調和平均

** Cohen の kappa 値
- Cohen's *kappa measure*
- 定義
  #+begin_quote
  #+begin_src latex
    \begin{align}
      p_{o}
      &=\frac{TP+TN}{TP+FP+TN+FN} \qquad\text{(accuracy)}\\
      p_{e}
      &=\frac{TP+FP}{TP+FP+TN+FN}\cdot\frac{TP+FN}{TP+FP+TN+FN}\\
      &\quad
	+\frac{FN+TN}{TP+FP+TN+FN}\cdot\frac{FP+TN}{TP+FP+TN+FN}\\
      \kappa
      &=
	\frac{p_{o}-p_{e}}{1-p_{e}}
	=
	1-\frac{1-p_{o}}{1-p_{e}}
    \end{align}
  #+end_src
  #+end_quote
  - 観測された精度と偶然の精度の比較


* 解析の事例
# 早稲田大学
** データについて
- 気象庁より取得した東京の気候データ \\
  - 気象庁 https://www.data.jma.go.jp/gmd/risk/obsdl/index.php
  - データ https://noboru-murata.github.io/multivariate-analysis/data/tokyo_weather.csv

** 気温と湿度による月の判別
- 温度と湿度による9/10月の線形判別
  #+begin_src R :file figs/09_lda.png :exports results :results graphics :tangle yes
    ### 東京の気象データによる判別分析
    library(MASS)
    library(caret)
    myCol <- rainbow(12)[c(2,5,8)]
    ## データの整理
    target <- c(9,10)
    tw_data <- read.csv("data/tokyo_weather.csv")
    tw_subset  <- subset(tw_data,
                         subset= month %in% target,
                         select=c(temp,humid,month))
    ## 線形判別関数を作成
    tw_lda <- lda(month ~ temp + humid, data=tw_subset)
    tw_lest <- predict(tw_lda)
    tw_lerr <- which(tw_lest$class!=tw_subset$month)
    ## 判別結果の図示
    myLine <- function(z) { # 判別境界を引くための関数
	a0<-as.vector(colMeans(z$means) %*% z$scaling)
	a<-c(a0/z$scaling[2],-z$scaling[1]/z$scaling[2])
	return(a)
    }
    with(tw_subset, 
	 plot(temp, humid, # 試験データの散布図
	      pch=month+6, col=myCol[month-8],
	      xlab="temperature",ylab="humidity",
	      main="linear discriminant"))
    with(tw_subset[tw_lerr,], 
	 points(temp, humid, # 訓練データの散布図
		pch=1, col="orchid", cex=2, lwd=2))
    abline(myLine(tw_lda), col="orange", lwd=2)
    rx <- with(tw_subset,range(temp))
    ry <- with(tw_subset,range(humid))
    sx <- pretty(rx,100)
    sy <- pretty(ry,100)
    myGrid <- expand.grid(temp=sx,humid=sy)
    ldesc <- predict(tw_lda,newdata=myGrid)
    image(sx,sy,add=TRUE,
	  matrix(as.numeric(ldesc$class),length(sx),length(sy)),
	  col=c(rgb(1,0,0,0.2),rgb(0,1,0,0.2)))
  #+end_src

#+CAPTION: 線形判別
#+NAME: fig:09_lda
#+ATTR_HTML: height 100%
#+ATTR_LATEX: :width 0.6\linewidth
[[file:figs/09_lda.png]]

#+reveal: split
- 温度と湿度による9/10月の2次判別
  #+begin_src R :file figs/09_qda.png :exports results :results graphics :tangle yes
    ## 2次判別関数を作成
    tw_qda <- qda(month ~ temp + humid, data=tw_subset)
    tw_qest <- predict(tw_qda) # 判別関数によるクラス分類結果の取得
    tw_qerr <- which(tw_qest$class!=tw_subset$month)
    ## 判別結果の図示
    ## 判別境界を描くのは複雑なので，色と形で代用する
    with(tw_subset, 
	 plot(temp, humid, # 試験データの散布図
	      pch=month+6, col=myCol[month-8],
	      xlab="temperature",ylab="humidity",
	      main="quadratic discriminant"))
    with(tw_subset[tw_qerr,], 
	 points(temp, humid, # 訓練データの散布図
		pch=1, col="orchid", cex=2, lwd=2))
    qdesc <- predict(tw_qda,newdata=myGrid)
    image(sx,sy,add=TRUE,
	  matrix(as.numeric(qdesc$class),length(sx),length(sy)),
	  col=c(rgb(1,0,0,0.2),rgb(0,1,0,0.2)))
  #+end_src
  
#+CAPTION: 2次判別
#+NAME: fig:09_qda
#+ATTR_HTML: height 100%
#+ATTR_LATEX: :width 0.6\linewidth
[[file:figs/09_qda.png]]

** 判別結果の比較
- 線形判別の混同行列
  #+begin_src R :exports results :tangle yes
    foo <- confusionMatrix(tw_lest$class, factor(tw_subset$month))$table
    bar <- matrix(0,3,3)
    bar[1,1] <- "予測値＼真値"
    bar[2:3,1] <- rownames(foo);bar[1,2:3] <- colnames(foo)
    bar[2:3,2:3] <- foo
    print(bar)
  #+end_src
- 2次判別の混同行列
  #+begin_src R :exports results :tangle yes
    foo <- confusionMatrix(tw_qest$class, factor(tw_subset$month))$table
    bar <- matrix(0,3,3)
    bar[1,1] <- "予測値＼真値"
    bar[2:3,1] <- rownames(foo);bar[1,2:3] <- colnames(foo)
    bar[2:3,2:3] <- foo
    print(bar)
  #+end_src

#+reveal: split
- 線形判別の評価指標
  #+begin_src R :exports results :tangle yes
    foo <- confusionMatrix(tw_lest$class, factor(tw_subset$month))$overall[1:2]
    matrix(c(names(foo),signif(foo,digits=3)),2,length(foo),byrow=TRUE)
  #+end_src
  #+begin_src R :exports results :tangle yes
    foo <- confusionMatrix(tw_lest$class, factor(tw_subset$month))$byClass[c(1,2,5,6,7)]
    matrix(c(names(foo),signif(foo,digits=3)),2,length(foo),byrow=TRUE)
  #+end_src
- 2次判別の評価指標
  #+begin_src R :exports results :tangle yes
    foo <- confusionMatrix(tw_qest$class, factor(tw_subset$month))$overall[1:2]
    matrix(c(names(foo),signif(foo,digits=3)),2,length(foo),byrow=TRUE)
  #+end_src
  #+begin_src R :exports results :tangle yes
    foo <- confusionMatrix(tw_qest$class, factor(tw_subset$month))$byClass[c(1,2,5,6,7)]
    matrix(c(names(foo),signif(foo,digits=3)),2,length(foo),byrow=TRUE)
  #+end_src

   
* 演習
:PROPERTIES:
:reveal_background: #fef4f4
:END:
# 早稲田大学
** 問題
:PROPERTIES:
:reveal_background: #fef4f4
:END:
- 以下の問に答えなさい
  - F-値，再現率，適合率の大小関係はどのようになるか
  - 2値判別(\(P=1,N=0\)とする)において
    正解ラベル\(Y\)と予測ラベル\(\hat{Y}\)の相関係数を
    \(TP,FP,TN,FN\)およびデータ数\(N\)
    を用いて表せ

** COMMENT 解答例
:PROPERTIES:
:reveal_background: #fef4f4
:END:
- 最大最小と平均の関係から以下が成り立つ
  #+begin_quote
  #+begin_src latex
    \begin{equation}
      \min(\text{再現率},\text{適合率})
      \le F_{1}
      \le\max(\text{再現率},\text{適合率})
    \end{equation}
  #+end_src
  さらに相加・相乗平均の関係から
  #+begin_src latex
    \begin{equation}
      F_{1}
      \le\text{(相乗平均)}
      \le\text{(相加平均)}
    \end{equation}
  #+end_src
  も成り立つ
  #+end_quote

#+reveal: split
- 相関係数の定義に従って計算すればよい
  #+begin_quote
  #+begin_src latex
    \begin{equation}
      \rho
      =
      \frac{\mathrm{Cov}(Y,\hat{Y})}
      {\sqrt{\mathrm{Var}(Y)\mathrm{Var}(\hat{Y})}}
    \end{equation}
  #+end_src
  #+end_quote

#+reveal: split
- 例えば分子の共分散は以下のように計算される
  #+begin_quote
  #+begin_src latex
    \begin{align}
      \mathrm{Cov}(Y,\hat{Y})
      &=
	\mathbb{E}[(Y-\mathbb{E}[Y])(\hat{Y}-\mathbb{E}[\hat{Y}])]\\
      &=
	\mathbb{E}[Y\hat{Y}]-\mathbb{E}[Y]\mathbb{E}[\hat{Y}]\\
      &=
	\frac{TP}{N}-\frac{TP+FN}{N}\frac{TP+FP}{N}\\
      &=
	\frac{TP(TP+FN+FP+TN)}{N^{2}}\\
      &\qquad-
	\frac{(TP+FN)(TP+FP)}{N^{2}}\\
      &=
	\frac{TP\cdot TN - FP\cdot FN}{N^{2}}
    \end{align}
  #+end_src
  #+end_quote
  - 平均は標本平均で置き換えた

#+reveal: split
- 同様に分母の分散は以下のようになる
  #+begin_quote
  #+begin_src latex
    \begin{align}
      \mathrm{Var}(Y)
      &=
	\mathbb{E}[Y^{2}]-\mathbb{E}[Y]^{2}\\
      &=
	\frac{(TP+FN)(TN+FP)}{N^{2}}\\
      \mathrm{Var}(\hat{Y})
      &=
	\mathbb{E}[\hat{Y}^{2}]-\mathbb{E}[\hat{Y}]^{2}\\
      &=
	\frac{(TP+FP)(TN+FN)}{N^{2}}
    \end{align}
  #+end_src
  #+end_quote

#+reveal: split
- したがって以下のようにまとめられる
  #+begin_quote
  #+begin_src latex
    \begin{equation}
      \rho=
      \frac{TP\cdot TN-FP\cdot FN}
      {\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}       
    \end{equation}
  #+end_src
  #+end_quote
  - これは Matthews correlation coefficient (MCC)
    と呼ばれる評価指標の一つである


* COMMENT 実習
:PROPERTIES:
:reveal_background: #fef4f4
:END:
# 東京大学
** データセットの準備
:PROPERTIES:
:reveal_background: #fef4f4
:END:
- 以下のデータセットを使用します
  - ~winequality-red.csv~
    #+begin_quote
    UC Irvine Machine Learning Repository で公開されている
    Wine Quality Data Set の一部
    #+end_quote
    [[https://archive.ics.uci.edu/ml/datasets/Wine+Quality]]
  - 以下に download せずに読み込む方法を紹介します
    #+begin_src R :eval no
      wq_org <- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv",
			 sep=";") # データの区切りが ";" となっている
      wq_data <- transform(wq_org,
			   quality=as.factor( # qualityを再分類
                               ifelse(quality %in% 7:10, "A",
                               ifelse(quality %in% 5:6, "B" ,"C"))))
    #+end_src

** R : 混同行列 ~caret::confusionMatrix()~
:PROPERTIES:
:reveal_background: #fef4f4
:END:
- ~caret~: 評価のためのパッケージ
- 判別結果の評価
  #+begin_src R :eval no
    install.packages("caret") # 右下ペインの package タブから install
    library(caret) # または require(caret) 
    confusionMatrix(data, reference)
    ## data: 判別関数による予測ラベル (factor)
    ## referenc: 真のラベル (上と同じfactorである必要がある)
  #+end_src

** 練習問題
:PROPERTIES:
:reveal_background: #fef4f4
:END:
- 前回と同様に東京の気候データの線形判別を行い，
  以下を確認しなさい
  - 10月と11月の気温と湿度のデータを抽出する
    #+begin_src R :eval no
      tw_data <- read.csv("data/tokyo_weather.csv")
      tw_subset  <- transform(subset(tw_data,
				     subset= month %in% c("10","11"),
				     select=c(temp,humid,month)),
			      month=as.factor(month)) # 因子にする
    #+end_src
  - 全てデータを用いて線形判別関数を構成する
  - 構成した判別関数の評価を行う

** 練習問題
:PROPERTIES:
:reveal_background: #fef4f4
:END:
- Wine Quality Data Set を用いて
  以下を確認しなさい
  - 全てデータを用いて線形判別関数を構成し，評価を行う
  - 全てデータを用いて2次判別関数を構成し，評価を行う

#+begin_src R :eval no :exports none :tangle yes
  ### 
  ### 練習問題 判別結果の評価
  ###

  ### 東京の気象データによる線形判別分析
  library(MASS)
  library(caret)

  ## 10月と11月の判別の例
  ## データの整理
  tw_data <- read.csv("data/tokyo_weather.csv")
  tw_subset  <- transform(subset(tw_data,
                                 subset= month %in% c("10","11"),
                                 select=c(temp,humid,month)),
                          month=as.factor(month)) # 因子にする
  ## 判別関数を作成
  tw_lda <- lda(month ~ temp + humid, data=tw_subset)
  ## 判別結果の評価
  tw_est <- predict(tw_lda)
  confusionMatrix(tw_est$class, tw_subset$month)

  ## 12ヶ月分のデータを用いた例 (説明変数は適宜選択せよ)
  tw_subset  <- transform(subset(tw_data,
                                 select=c(temp,solar,wind,humid,month)),
                          month=as.factor(month)) 
  ## 判別関数を作成
  tw_lda <- lda(month ~ ., # 右辺の . は month 以外の全てを説明変数として指定
                data=tw_subset)
  ## 判別結果の評価
  tw_est <- predict(tw_lda)
  confusionMatrix(tw_est$class, tw_subset$month)
  confusionMatrix(tw_est$class, tw_subset$month)$table
  confusionMatrix(tw_est$class, tw_subset$month)$overall
  confusionMatrix(tw_est$class, tw_subset$month)$byClass

  ## Wine Quality Data Set を用いた判別分析
  wq_org <- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv",
                     sep=";")
  table(wq_org$quality) 
  wq_data <- transform(wq_org,
                       quality=as.factor(
                           ifelse(quality %in% 7:10, "A",
                           ifelse(quality %in% 5:6, "B" ,"C"))))
  ## 判別関数を作成
  wq_lda <- lda(quality ~ ., data=wq_data)
  wq_qda <- qda(quality ~ ., data=wq_data)
  ## 判別結果の評価
  confusionMatrix(predict(wq_lda)$class, wq_data$quality)
  confusionMatrix(predict(wq_qda)$class, wq_data$quality)
#+end_src

** COMMENT 演習: さまざまな評価値
:PROPERTIES:
:reveal_background: #EEEEFF
:END:
- 前回用いたデータについて，
  さまざまな評価値を計算してみよう



* 予測誤差
** 訓練誤差と予測誤差
- *訓練誤差* :
  既知データに対する誤り (training error)
- *予測誤差* :
  未知データに対する誤り (predictive error)
- 訓練誤差は予測誤差より良くなることが多い 
- 既知データの判別に特化している可能性がある
  - 過適応 (over-fitting)
  - 過学習 (over-training)

** 交叉検証
- データを訓練データと試験データに分割して用いる
  - *訓練データ* :
    判別関数を構成する (training data)
  - *試験データ* :
    予測精度を評価する (test data)
- データの分割に依存して予測誤差の評価が偏る
- 偏りを避けるために複数回分割を行ない評価する
- "交差"と書く場合もある
# データ分割の偏りによる精度評価の

** 交叉検証法
- *cross-validation (CV)* 
- \(k\)-重交叉検証法 (\(k\)-fold cross-validation; \(k\)-fold CV)
  - \(n\) 個のデータを \(k\) ブロックにランダムに分割
  - 第 \(i\) ブロックを除いた \(k-1\) ブロックで判別関数を推定
  - 除いておいた第 \(i\) ブロックで予測誤差を評価
  - \(i=1,\dotsc,k\) で繰り返し \(k\) 個の予測誤差で評価 (平均や分散)
- leave-one-out法 (leave-one-out CV; LOO-CV)
  - \(k=n\) として上記を実行


* COMMENT 実習
:PROPERTIES:
:reveal_background: #fef4f4
:END:
# 東京大学
** R : LOO交叉検証法
:PROPERTIES:
:reveal_background: #fef4f4
:END:
- 関数 ~lda()~ と ~qda()~ はオプションで LOO交叉検証を行うことができる
- オプションの指定方法
  #+begin_src R :eval no
    est <- lda(formula, data, CV=TRUE)
    est$class # LOO CV による予測結果
    ## 特定のデータを除いて判別関数を構成し，そのデータの予測を行っている
    est <- qda(formula, data, CV=TRUE)
    est$class # LOO CV による予測結果
    ## 2次判別についても同様
  #+end_src

** R : k-重交叉検証法 ~caret::train()~
:PROPERTIES:
:reveal_background: #fef4f4
:END:
- ~caret~ パッケージの関数 ~train()~ で実行可能
  #+begin_src R :eval no
    train(formula, data,
	  method,
	  trControl=trainControl(method="cv", number))
    ## formula: Rの式 
    ## data: データフレーム
    ## method: 推定を行う関数 method="lda"/"qda" などを指定
    ## trControl: 学習方法の指定
    ## trainControl のオプション
    ##  method: 評価方法など指定 method="cv"/"LOOCV"
    ##  number: k-重交叉検証のブロック数 (k)
  #+end_src

** 練習問題
:PROPERTIES:
:reveal_background: #fef4f4
:END:
- Wine Quality Data Set を用いた
  線形判別と2次判別に関して，以下を行いなさい
  - LOO交叉検証法を用いて予測誤差の評価を行いなさい
  - k-重交叉検証法を用いて予測誤差の評価を行いなさい

#+begin_src R :eval no :exports none :tangle yes
  ### 
  ### 練習問題 予測誤差の評価
  ###

  ### Wine Quality Data Set による誤差の評価
  library(MASS)  # 既に読み込んでいれば不要
  library(caret) # 既に読み込んでいれば不要

  ## データの整理 (既に整理してあれば不要)
  wq_org <- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv",
                     sep=";")
  wq_data <- transform(wq_org,
                       quality=as.factor(
                           ifelse(quality %in% 7:10, "A",
                           ifelse(quality %in% 5:6, "B" ,"C"))))

  ## LOO CV の例 (lda/qdaは標準で装備している)
  ## 線形判別
  wq_lda <- lda(quality ~ ., data=wq_data) 
  wq_ldloo <- lda(quality ~ ., data=wq_data, CV=TRUE)
  confusionMatrix(predict(wq_lda)$class, wq_data$quality)$table
  confusionMatrix(wq_ldloo$class, wq_data$quality)$table
  ## 線形判別の過学習は微小

  ## 2次判別
  wq_qda <- qda(quality ~ ., data=wq_data) 
  wq_qdloo <- qda(quality ~ ., data=wq_data, CV=TRUE)
  confusionMatrix(predict(wq_qda)$class, wq_data$quality)$table
  confusionMatrix(wq_qdloo$class, wq_data$quality)$table
  ## 2次判別は若干過学習している

  ## 予測誤差の比較
  confusionMatrix(wq_ldloo$class, wq_data$quality)$overall
  confusionMatrix(wq_qdloo$class, wq_data$quality)$overall
  ## 予測誤差の観点からは線形判別の方が良さそう

  ## k-重交叉検証は caret package の機能を利用して求めることができる
  (train(quality ~., data=wq_data, method="lda",
         trControl=trainControl(method="cv", number=10)))
  (train(quality ~., data=wq_data, method="qda",
         trControl=trainControl(method="cv", number=10)))
  ## LOO CV も利用することができるが，計算は遅い
  (train(quality ~., data=wq_data, method="lda",
         trControl=trainControl(method="LOOCV")))
  (train(quality ~., data=wq_data, method="qda",
         trControl=trainControl(method="LOOCV")))
#+end_src
  
** COMMENT 演習: 予測誤差の評価
:PROPERTIES:
:reveal_background: #EEEEFF
:END:
- [[./code/10-valid.r][10-valid.r]] を確認してみよう

** COMMENT 演習: 交叉検証による評価
:PROPERTIES:
:reveal_background: #EEEEFF
:END:
- [[./code/10-cv.r][10-cv.r]] を確認してみよう

** COMMENT 演習
:PROPERTIES:
:reveal_background: #EEEEFF
:END:
- 前回用いたデータについて線形・2次どちらの判別方法が望ましいか検証してみよう


* 解析の事例
# 早稲田大学
** データについて
- UC Irvine Machine Learning Repository の公開データ
  - [[https://archive.ics.uci.edu/ml/datasets/Wine+Quality]]
    #+begin_quote
    Wine Quality Data Set

    P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. 
    Modeling wine preferences by data mining from physicochemical properties.
    In Decision Support Systems, Elsevier, 47(4):547-553. ISSN: 0167-9236.
    #+end_quote
    以下では ~winequality-red.csv~ を利用

#+reveal: split
- データ概要
  - データ数 1599
  - 説明変数 (based on physicochemical tests)
    #+begin_quote
    1 - fixed acidity \\
    2 - volatile acidity \\
    3 - citric acid \\
    4 - residual sugar \\
    5 - chlorides \\
    6 - free sulfur dioxide \\
    7 - total sulfur dioxide \\
    8 - density \\
    9 - pH \\
    10 - sulphates \\
    11 - alcohol \\
    #+end_quote
  - 目的変数  (based on sensory data)
    #+begin_quote
    12 - quality (score between 0 and 10) \\
    #+end_quote
    - ただし解析では A,B,C の3値に集計

#+reveal: split
- 実際のデータの一部
  #+begin_src R :exports results :tangle yes
    ## データの整理 (既に整理してあれば不要)
    wq_org <- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv",
                       sep=";")
    wq_data <- transform(wq_org,
                         quality=as.factor(
                             ifelse(quality %in% 7:10, "A",
                             ifelse(quality %in% 5:6, "B" ,"C"))))
    rbind(names(wq_data)[1:4],data.frame(head(wq_data[,1:4], 10)))
  #+end_src

#+reveal: split
- 実際のデータの一部 (続き)
  #+begin_src R :exports results :tangle yes
    rbind(names(wq_data)[5:8],data.frame(head(wq_data[,5:8], 10)))
  #+end_src

#+reveal: split
- 実際のデータの一部 (続き) 
  #+begin_src R :exports results :tangle yes
    rbind(names(wq_data)[9:ncol(wq_data)],data.frame(head(wq_data[,9:ncol(wq_data)], 10)))
  #+end_src

** LOO交叉検証による予測誤差の評価
- 線形判別 (訓練誤差/予測誤差)
  #+begin_src R :exports results :tangle yes
    wq_lda <- lda(quality ~ ., data=wq_data) 
    wq_ldloo <- lda(quality ~ ., data=wq_data, CV=TRUE)
    foo <- confusionMatrix(predict(wq_lda)$class, wq_data$quality)$table
    bar <- matrix(0,4,4)
    bar[1,1] <- "予測値＼真値"
    bar[2:4,1] <- rownames(foo);bar[1,2:4] <- colnames(foo)
    bar[2:4,2:4] <- foo
    print(bar)
  #+end_src
  #+begin_src R :exports results :tangle yes
    foo <- confusionMatrix(wq_ldloo$class, wq_data$quality)$table
    bar <- matrix(0,4,4)
    bar[1,1] <- "予測値＼真値"
    bar[2:4,1] <- rownames(foo);bar[1,2:4] <- colnames(foo)
    bar[2:4,2:4] <- foo
    print(bar)
  #+end_src
  - 線形判別の過学習は微小


#+reveal: split
- 2次判別 (訓練誤差/予測誤差)
  #+begin_src R :exports results :tangle yes
    wq_qda <- qda(quality ~ ., data=wq_data) 
    wq_qdloo <- qda(quality ~ ., data=wq_data, CV=TRUE)
    foo <- confusionMatrix(predict(wq_qda)$class, wq_data$quality)$table
    bar <- matrix(0,4,4)
    bar[1,1] <- "予測値＼真値"
    bar[2:4,1] <- rownames(foo);bar[1,2:4] <- colnames(foo)
    bar[2:4,2:4] <- foo
    print(bar)
  #+end_src
  #+begin_src R :exports results :tangle yes
    foo <- confusionMatrix(wq_qdloo$class, wq_data$quality)$table
    bar <- matrix(0,4,4)
    bar[1,1] <- "予測値＼真値"
    bar[2:4,1] <- rownames(foo);bar[1,2:4] <- colnames(foo)
    bar[2:4,2:4] <- foo
    print(bar)
  #+end_src
  - 2次判別は若干過学習している

#+reveal: split
- 予測誤差の比較 (線形)
  #+begin_src R :exports results :tangle yes
    foo <- confusionMatrix(wq_ldloo$class, wq_data$quality)$overall[1:2]
    matrix(c(names(foo),signif(foo,digits=3)),2,length(foo),byrow=TRUE)
  #+end_src
  #+begin_src R :exports results :tangle yes
    foo <- confusionMatrix(wq_ldloo$class, wq_data$quality)$byClass[,c(1,2,5,6,7)]
    bar <- matrix(c(colnames(foo),signif(foo,digits=3)),nrow(foo)+1,ncol(foo),byrow=TRUE)
    bar <- cbind(c("",rownames(foo)),bar)
    print(bar)
  #+end_src

#+reveal: split
- 予測誤差の比較 (2次)
  #+begin_src R :exports results :tangle yes
    foo <- confusionMatrix(wq_qdloo$class, wq_data$quality)$overall[1:2]
    matrix(c(names(foo),signif(foo,digits=3)),2,length(foo),byrow=TRUE)
  #+end_src
  #+begin_src R :exports results :tangle yes
    foo <- confusionMatrix(wq_qdloo$class, wq_data$quality)$byClass[,c(1,2,5,6,7)]
    bar <- matrix(c(colnames(foo),signif(foo,digits=3)),nrow(foo)+1,ncol(foo),byrow=TRUE)
    bar <- cbind(c("",rownames(foo)),bar)
    print(bar)
  #+end_src
  - 予測誤差の観点からは線形判別の方が良さそう

    
* 次週の予定
- *第1日 : クラスタ分析の考え方と階層的方法*
- 第2日 : 非階層的方法と分析の評価

* Footnotes
* COMMENT ローカル変数
# Local Variables:
# org-latex-listings: minted
# End:
  
   
   

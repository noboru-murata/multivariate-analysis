#+TITLE: クラスタ分析 
#+SUBTITLE: 非階層的方法と分析の評価
#+AUTHOR: 村田 昇
#+EMAIL: noboru.murata@gmail.com
#+DATE: 
#+STARTUP: hidestars content indent
# Time-stamp: <2024-12-20 11:54:04 mura>
:REVEAL:
#+SETUPFILE: "./reveal.js/local/mycourse.org"
# C-c C-x C-v でinlineを切り替え
# <m C-i でlatex block (math env用)
# C-c '
:END:

* COMMENT メモ
[[file:README.org::第11講]]
  
* COMMENT 講義の内容
:PROPERTIES:
:ID:       1957D10C-281F-41A0-ACE9-1119E2E55796
:END:
# 早稲田大学
- 第1回 : クラスタ分析の考え方と階層的方法
- *第2回 : 非階層的方法と分析の評価*

#+begin_src R :exports none :tangle no
  setwd("~/Desktop/lectures/mva/course")
#+end_src
#+begin_src R :exports none
  ### 第11講 資料
  library(conflicted)
  conflicts_prefer(
    dplyr::filter(),
    dplyr::select(),
    dplyr::lag(),
    )
  library(tidyverse)
  library(GGally)
  library(ggfortify)
  library(cluster)
  library(ggdendro)
  library(gt)
  #' 日本語表示・色の設定 (ggplot)
  theme_set(theme_gray(base_size = 16))
  if(Sys.info()[["sysname"]] == "Darwin") { # MacOSか確認
    if(length(grep("BIZUDPGothic", systemfonts::system_fonts()[["name"]]))>0) 
      theme_update(text = element_text(family = "BIZUDGothic-Regular"))
    else
      theme_update(text = element_text(family = "HiraMaruProN-W4"))}
  library(see)
  options(ggplot2.discrete.colour = function() scale_colour_material(),
          ggplot2.discrete.fill = function() scale_fill_material())
#+end_src

* 講義概要
:PROPERTIES:
:ID:       6411F06A-9DF9-4E9A-AE03-52D6A80FE3EF
:END:
# 東京大学
- 第1回 : クラスタ分析の考え方と階層的方法
- *第2回 : 非階層的方法と分析の評価*

#+begin_src R :exports none :tangle no
  setwd("~/Desktop/lectures/u-tokyo/autumn/course")
  library(gt)
#+end_src
#+begin_src R :exports none 
  ### 第11講 サンプルコード
  library(conflicted)
  conflicts_prefer(
    dplyr::filter(),
    dplyr::select(),
    dplyr::lag(),
  )
  library(tidyverse)
  library(ggfortify)
  library(cluster)
  library(ggdendro)
  library(gt)
#+end_src


  
* クラスタ分析の復習
** クラスタ分析
- クラスタ分析 (*cluster analysis*) の目的
  #+begin_quote
  個体の間に隠れている
  *集まり=クラスタ*
  を個体間の"距離"にもとづいて発見する方法
  #+end_quote
- 個体間の類似度・距離(非類似度)を定義
  - 同じクラスタに属する個体どうしは似通った性質
  - 異なるクラスタに属する個体どうしは異なる性質
- さらなるデータ解析やデータの可視化に利用
- 教師なし学習の代表的な手法の一つ

** クラスタ分析の考え方
- 階層的方法
  - データ点およびクラスタの間に *距離* を定義
  - 距離に基づいてグループ化
    - 近いものから順にクラスタを *凝集*
    - 近いものが同じクラスタに残るように *分割*
- 非階層的方法
  - クラスタの数を事前に指定
  - クラスタの *集まりの良さ* を評価する損失関数を定義
  - 損失関数を最小化するようにクラスタを形成

** COMMENT 階層的方法における凝集的手続き
1. データ・クラスタ間の距離を定義する
   - データ点とデータ点の距離
   - クラスタとクラスタの距離
2. データ点およびクラスタ間の距離を求める
3. 最も近い2つを統合し新たなクラスタを形成する
4. クラスタ数が1つになるまで2-3の手続きを繰り返す

** COMMENT 階層的方法における凝集的手続き
#+begin_leftcol60
1. データ・クラスタ間の距離を定義
   - データ点間の距離
   - クラスタ間の距離
2. データ点およびクラスタ間の距離を計算
3. 最も近い2つを統合し新たなクラスタを形成
4. クラスタ数が1つになるまで2-3の手続きを繰り返す
#+end_leftcol60    
#+begin_rightcol40
#+header: :width 600 :height 1000 :res 100
#+begin_src R :file figs/11_hclst.png :exports results :results graphics
  library(cluster)
  js_data <- read.csv("data/japan_social.csv", row.names=1)
  pref <- read.csv(file="data/prefecture.csv", row.names=1)
  rownames(js_data) <- pref$jp
  myPlot <- function(k) {
    tmpa <- js_data[8:14,]
    tmpb <- list(c(1,2,3,4,1,6,7),
		 c(1,2,3,1,1,6,7),
		 c(1,2,2,1,1,6,7),
		 c(1,2,2,1,1,6,1),
		 c(1,1,1,1,1,6,1),
		 c(1,1,1,1,1,1,1))
    clusplot(x=tmpa,
	     clus=c(1,2,3,4,5,6,7),
	     diss=FALSE,
	     stand=TRUE, lines=0, labels=3, 
	     main=NULL, sub=NULL, cex=1,
	     xlab="", ylab="", axes=FALSE,
	     xlim=c(-2.5,1.5), ylim=c(-1.5,2.2),
	     col.p="blue", col.clus="white", shade=FALSE)
    box()
    if(k>0) {
      for(i in 1:k) {
	clusplot(x=tmpa,
		 clus=tmpb[[i]],
		 diss=FALSE,
		 stand=TRUE, add=TRUE, span=FALSE,
		 lines=0, lwd=2, col.p="blue", col.clus="orange")
      }
    }
  }
  if(Sys.info()["sysname"]=="Darwin"){par(family="BIZUDGothic-Regular")}
  par(mfrow=c(4,2), mar=rep(0.5,4))
  myPlot(0)
  myPlot(1)
  myPlot(2)
  myPlot(3)
  myPlot(4)
  myPlot(5)
  myPlot(6)
  plot(agnes(scale(js_data[8:14,])), which.plots=2,
       main="",sub="",xlab="")
#+end_src

#+CAPTION: 凝集的手続きの例
#+NAME: fig:11_hclst
#+ATTR_HTML: height 100%
#+ATTR_LATEX: :width 0.6\linewidth
[[file:figs/11_hclst.png]]
#+end_rightcol40    

** 階層的クラスタリング
:PROPERTIES:
:ID:       41C635C9-2F63-41F1-B272-09A6D04A78B5
:END:
#+begin_leftcol
- 凝集的手続き
  1. データ・クラスタ間の距離を定義
     - データ点間の距離
     - クラスタ間の距離
  2. データ点およびクラスタ間の距離を計算
  3. 最も近い2つを統合し新たなクラスタを形成
  4. クラスタ数が1つになるまで2-3の手続きを繰り返す
#+end_leftcol
#+begin_rightcol
#+header: :width 600 :height 1000
#+begin_src R :file figs/11_hclst.png :exports results :results graphics :tangle no
  library(cluster)
  js_data <- bind_cols(
    read_csv(file="data/japan_social.csv"),
    read_csv(file="data/prefecture.csv"))
  myPlot <- function(k) {
    if(Sys.info()["sysname"]=="Darwin"){par(family="BIZUDGothic-Regular")}
    tmpa <- js_data |>
      slice(8:14) |>
      select(2:6,jp) |>
      column_to_rownames(var = "jp")
    # tmpa <- js_data[8:14,]
    tmpb <- list(c(1,2,3,4,1,6,7),
                 c(1,2,3,1,1,6,7),
                 c(1,2,2,1,1,6,7),
                 c(1,2,2,1,1,6,1),
                 c(1,1,1,1,1,6,1),
                 c(1,1,1,1,1,1,1))
    clusplot(x=tmpa,
             clus=c(1,2,3,4,5,6,7),
             diss=FALSE,
             stand=TRUE, lines=0, labels=3, 
             main=NULL, sub=NULL, cex=1.5,
             xlim=c(-2.5,2.5), ylim=c(-2.5,2.5),
             xaxt="n", yaxt="n", ann=FALSE,
             col.p="blue", col.txt="darkgray", col.clus="white", shade=FALSE)
    if(k>0) {
      for(i in 1:k) {
        clusplot(x=tmpa,
                 clus=tmpb[[i]],
                 diss=FALSE, cex=0.2,
                 stand=TRUE, add=TRUE, span=FALSE,
                 lines=0, lwd=3, col.p="blue", col.clus="orange")
      }
    }
  }
  if(Sys.info()["sysname"]=="Darwin"){par(family="BIZUDGothic-Regular")}
  par(mfrow=c(4,2), mar=rep(0.5,4))
  for(i in 0:6) myPlot(i)
  js_data |>
    slice(8:14) |>
    select(2:6,jp) |>
    column_to_rownames(var = "jp") |>
    scale() |>
    agnes() |>
    plot(which.plots=2, main="",sub="",xlab="")
#+end_src

#+caption: 凝集的手続きの例
#+name: fig:11_hclst
#+attr_html: height 100%
#+attr_latex: :width 0.6\linewidth
[[file:figs/11_hclst.png]]
#+end_rightcol


* 非階層的方法
** 非階層的方法の手続き
- 対象の変数 : \(\boldsymbol{X}=(X_1,X_2,\dotsc,X_{d})^{\mathsf{T}}\) (\(d\)次元)
- 観測データ : \(n\) 個の個体の組
  #+begin_quote
  \begin{equation}
    \{\boldsymbol{x}_{i}\}_{i=1}^{n}
    =
    \{(x_{i1},x_{i2},\dotsc,x_{id})^{\mathsf{T}}\}_{i=1}^{n}
  \end{equation}
  #+end_quote
- 個体とクラスタの対応 \(C\) を推定 
  #+begin_quote
  \begin{equation}
    C(i)
    =\text{(個体 \(i\) が属するクラスタ番号)}
  \end{equation}
  #+end_quote
  - 対応 \(C\) の *全体の良さ* を評価する損失関数を設定
  - 観測データ
    \(\{\boldsymbol{x}_{i}\}_{i=1}^{n}\)
    に最適な対応
    \(\{C(i)\}_{i=1}^{n}\) を決定

** @@latex:@@\(k\)-平均法の損失関数
- クラスタの個数 \(k\) を指定
- 2つの個体 \(i,i'\) の *近さ=損失* を距離の二乗で評価
  #+begin_quote
  \begin{equation}
    \|\boldsymbol{x}_i-\boldsymbol{x}_{i'}\|^2
    =
    \sum_{j=1}^{d}(x_{ij}-x_{i'j})^2
  \end{equation}
  #+end_quote
- 損失関数 \(W(C)\) : クラスタ内の平均の近さを評価
  #+begin_quote
  \begin{equation}
    W(C)
    =
    \sum_{l=1}^k\frac{1}{n_l}\sum_{i:C(i)=l}\sum_{i':C(i')=l}\|\boldsymbol{x}_i-\boldsymbol{x}_{i'}\|^2
  \end{equation}
  #+end_quote
#  - (\(n_l\) はクラスタ \(l\) に属する個体数)

** @@latex:@@\(k\)-平均法の性質
- クラスタ \(l\) に属する個体の平均
  #+begin_quote
  \begin{equation}
    \bar{\boldsymbol{x}}_l
    =
    \frac{1}{n_l}\sum_{i:C(i)=l}\boldsymbol{x}_i,
    \quad\text{(\(n_l\) はクラスタ \(l\) に属する個体数)}
  \end{equation}
  #+end_quote
- 損失関数 \(W(C)\) の等価な表現
  #+begin_quote
  \begin{equation}
    W(C)
    =
    2\sum_{l=1}^k\sum_{i:C(i)=l}\|\boldsymbol{x}_i-\bar{\boldsymbol{x}}_{l}\|^2
  \end{equation}
  #+end_quote
- 最適な対応 \(C\) : クラスタ内変動の総和が最小


* COMMENT 演習
:PROPERTIES:
:reveal_background: #fef4f4
:END:
# 早稲田大学
** 問題
:PROPERTIES:
:reveal_background: #fef4f4
:END:
- 以下の問に答えなさい
  - 損失関数 \(W(C)\) の等価な表現を示しなさい
    #+begin_quote
    \begin{align}
      W(C)
      &=
        \sum_{l=1}^k\frac{1}{n_l}\sum_{i:C(i)=l}\sum_{i':C(i')=l}\|\boldsymbol{x}_i-\boldsymbol{x}_{i'}\|^2\\
      &=
        2\sum_{l=1}^k\sum_{i:C(i)=l}\|\boldsymbol{x}_i-\bar{\boldsymbol{x}}_{l}\|^2
    \end{align}
    #+end_quote
  - 以下の\(\hat{\boldsymbol{\mu}}\)を求めなさい
    #+begin_quote
    \begin{equation}
      \hat{\boldsymbol{\mu}}
      =\arg\min_{\mu}
      \sum_{i:C(i)=l}\|\boldsymbol{x}_i-\boldsymbol{\mu}\|^2
    \end{equation}
    #+end_quote

** 解答例
:PROPERTIES:
:reveal_background: #fef4f4
:END:
- 対称性に注意して標本平均のまわりで展開
  #+begin_quote
  \begin{align}
    &\sum_{l=1}^k\frac{1}{n_l}\sum_{i:C(i)=l}\sum_{i':C(i')=l}
      \|\boldsymbol{x}_i-\boldsymbol{x}_{i'}\|^2\\
    &=
      \sum_{l=1}^k\frac{1}{n_l}\sum_{i:C(i)=l}\sum_{i':C(i')=l}
      \|\boldsymbol{x}_i-\bar{\boldsymbol{x}}_{l}+\bar{\boldsymbol{x}}_{l}-\boldsymbol{x}_{i'}\|^2\\
    &=
      \sum_{l=1}^k\frac{2}{n_l}\sum_{i:C(i)=l}\sum_{i':C(i')=l}
      \|\boldsymbol{x}_i-\bar{\boldsymbol{x}}_{l}\|^2\\
    &\quad-
      \sum_{l=1}^k\frac{2}{n_l}\sum_{i:C(i)=l}\sum_{i':C(i')=l}
      (\boldsymbol{x}_i-\bar{\boldsymbol{x}}_{l})^{\mathsf{T}}
      (\boldsymbol{x}_{i'}-\bar{\boldsymbol{x}}_{l})
  \end{align}
  #+end_quote

#+reveal: split
- 中心化したデータの標本平均が0であることを利用
  #+begin_quote
  \begin{align}
    &=
      2\sum_{l=1}^k\sum_{i:C(i)=l}
      \|\boldsymbol{x}_i-\bar{\boldsymbol{x}}_{l}\|^2\\
    &\quad-
      \sum_{l=1}^k\frac{2}{n_l}
      \sum_{i:C(i)=l}(\boldsymbol{x}_i-\bar{\boldsymbol{x}}_{l})^{\mathsf{T}}
      \sum_{i':C(i')=l}(\boldsymbol{x}_{i'}-\bar{\boldsymbol{x}}_{l})\\
    &=
      2\sum_{l=1}^k\sum_{i:C(i)=l}
      \|\boldsymbol{x}_i-\bar{\boldsymbol{x}}_{l}\|^2
  \end{align}
  #+end_quote

#+reveal: split
- 以下の不等式が成立
  #+begin_quote
  \begin{align}
    \sum_{i:C(i)=l}\|\boldsymbol{x}_{i}-\boldsymbol{\mu}\|^{2}
    &=
      \sum_{i:C(i)=l}
      \|\boldsymbol{x}_{i}-\bar{\boldsymbol{x}}_{l}
      +
      \bar{\boldsymbol{x}}_{l}-\boldsymbol{\mu}\|^{2}\\
    &=
      \sum_{i:C(i)=l}
      \|\boldsymbol{x}_{i}-\bar{\boldsymbol{x}}_{l}\|^{2}
      +
      \sum_{i:C(i)=l}
      \|\bar{\boldsymbol{x}}_{l}-\boldsymbol{\mu}\|^{2}\\
    &\quad+
      2\sum_{i:C(i)=l}
      (\boldsymbol{x}_{i}-\bar{\boldsymbol{x}}_{l})^{\mathsf{T}}
      (\bar{\boldsymbol{x}}_{l}-\boldsymbol{\mu})\\
    &=
      \sum_{i:C(i)=l}
      \|\boldsymbol{x}_{i}-\bar{\boldsymbol{x}}_{l}\|^{2}
      +
      n_{l}\|\bar{\boldsymbol{x}}_{l}-\boldsymbol{\mu}\|^{2}\\
    &\ge
      \sum_{i:C(i)=l}
      \|\boldsymbol{x}_{i}-\bar{\boldsymbol{x}}_{l}\|^{2}
  \end{align}
  #+end_quote

#+reveal: split
- 等号の成立の条件より
  #+begin_quote
  \begin{equation}
    \hat{\boldsymbol{\mu}}
    =\arg\min_{\mu}
    \sum_{i:C(i)=l}\|\boldsymbol{x}_i-\boldsymbol{\mu}\|^2
    =\bar{\boldsymbol{x}}_{l}
  \end{equation}
  クラスタの標本平均を中心とすればよい
  #+end_quote


* 近似的な最適化
** クラスタ対応の最適化
- 最適化 : 損失関数 \(W(C)\) を最小とする \(C\) を決定
- 貪欲な \(C\) の探索
  - 原理的には全ての値を計算すればよい
  - 可能な \(C\) の数 : \(k^n\) 通り (有限個のパターン)
  - サンプル数 \(n\) が小さくない限り実時間での実行は不可能
- 近似的な \(C\) の探索
  - いくつかのアルゴリズムが提案されている
  - 基本的な考え方 : *Lloyd-Forgyのアルゴリズム*
    #+begin_quote
    標本平均と変動の平方和の性質を利用
    \begin{equation}
      \bar{\boldsymbol{x}}_l
      =\arg\min_{\mu}
      \sum_{i:C(i)=l}\|\boldsymbol{x}_i-\boldsymbol{\mu}\|^2
      \quad
      \text{(クラスタ\(l\)の標本平均)}
    \end{equation}
    #+end_quote

** Lloyd-Forgyのアルゴリズム
1. クラスタ中心の初期値 
   \(\boldsymbol{\mu}_1,\boldsymbol{\mu}_2,\dots,\boldsymbol{\mu}_k\) を与える
2. 各データの所属クラスタ番号 \(C(i)\) を求める
   #+begin_quote
   \begin{equation}
     C(i)
     =
     \arg\min_l\|\boldsymbol{x}_i-\boldsymbol{\mu}_l\|
   \end{equation}
   #+end_quote
3. 各クラスタ中心 \(\boldsymbol{\mu}_l\;(l=1,2,\dotsc,k)\) を更新する
   #+begin_quote
   \begin{equation}
     \boldsymbol{\mu}_l
     =
     \frac{1}{n_l}\sum_{i:C(i)=l}\boldsymbol{x}_i,
     \quad
     n_l=|\{\boldsymbol{x}_i|C(i)=l\}|
   \end{equation}
   # (\(n_l\) は \(C(i)=l\) となるデータの総数)
   #+end_quote
4. 中心が変化しなくなるまで 2,3 を繰り返す

** アルゴリズムの性質
- 結果は *確率的*
  - 初期値 \(\boldsymbol{\mu}_1,\boldsymbol{\mu}_2,\dots,\boldsymbol{\mu}_k\) に依存
  - アルゴリズムの成否は確率的なため，最適解が得られない場合もある
- 一般には複数の初期値をランダムに試して損失を最小とする解を採用する
- 平均の代わりにメドイド (medoid; 中心にある観測値) を用いる方法もある
  #+begin_quote
  \begin{equation}
    \boldsymbol{x}^{\mathrm{medoid}}_{l}
    =\arg\min_{\boldsymbol{x}_{i}}
    \sum_{i':C(i')=l}
    \|\boldsymbol{x}_{i}-\boldsymbol{x}_{i'}\|^2
  \end{equation}
  #+end_quote

** 事例
:PROPERTIES:
:ID:       5DF1EC41-AF81-47B0-A847-0EB32710158C
:END:
- 関東・関西圏を除く好きなおむすびの具
#+begin_src R :exports none
  om_data <- bind_cols(
    read_csv(file="data/omusubi.csv"),
    read_csv(file="data/prefecture.csv"))
  om_subset <- om_data |>
    select(ume:etc,jp) |>
    slice(-c(8:14,24:30)) |>
    column_to_rownames(var = "jp") |>
    set_names(c("梅","鮭","昆布","鰹","明太子","鱈子","ツナ","その他")) 
  n <- nrow(om_subset)
#+end_src
#+begin_src R :eval no :exports none
  om_subset |> View() # 左上ペインに表として表示
#+end_src
#+begin_src R :exports results :results output html :tangle no
  #' データの表示(reveal用)
  om_subset |>
    mutate(県名 = rownames(om_subset), .before = 1) |>
    slice_head(n = 15) |> 
    gt() |>
    as_raw_html()
#+end_src
#+begin_src R :exports results :results value scalar latex :tangle no
  #' データの表示(latex用)
  om_subset |>
    mutate(県名 = rownames(om_subset), .before = 1) |>
    gt() |>
    tab_options(table.font.size = 9) |>
    as_latex() |> as.character()
#+end_src

#+reveal: split
#+begin_src R :file figs/11_nhclst0.png :exports results :results graphics :tangle no
  jdx <- 1:ncol(om_subset) # jdx <- sample(ncol(om_subset),2)
  om_pca <- prcomp(om_subset[,jdx])

  if(Sys.info()["sysname"]=="Darwin"){par(family="BIZUDGothic-Regular")}
  plot(predict(om_pca),
       col="blue", pch=19, cex=0.5,
       xaxt="n", yaxt="n", ann=FALSE)
  text(transform(predict(om_pca), PC2=PC2+0.5),
       labels=rownames(om_subset), col="blue", cex=1)
#+end_src
#+caption: 非階層的クラスタリング
#+name: fig:11_nhclst0
#+attr_html: height 100%
#+attr_latex: :width 0.6\linewidth
[[file:figs/11_nhclst0.png]]
#+reveal: split
#+begin_src R :file figs/11_nhclst1.png :exports results :results graphics :tangle no
  ## 図示のための関数
  myPlot <- function(cntr) {
    dsy <- daisy(rbind(om_subset[,jdx],cntr))
    clst <- apply(as.matrix(dsy)[1:n,(1:k)+n],
                  1,
                  function(x){which.min(x)})
    plot(predict(om_pca), col=clst, pch=clst, type="n",
         xaxt="n", yaxt="n", ann=FALSE)
    text(predict(om_pca), labels=clst, col=clst, cex=1.5)
    points(predict(om_pca,newdata=cntr), col=1:k, pch=19, cex=2)
    cntr <- aggregate(. ~ clst,
                      data=data.frame(om_subset[,jdx],clst),
                      mean)[,-1]
    return(cntr)
  }
  set.seed(1212)
  k <- 5
  idx <- sample(n,k)
  cntr <- om_subset[idx,jdx]
  ## 
  cntr <- myPlot(cntr)
#+end_src
#+caption: Lloyd-Forgyのアルゴリズム (その1)
#+name: fig:11_nhclst1
#+attr_html: height 100%
#+attr_latex: :width 0.6\linewidth
[[file:figs/11_nhclst1.png]]

#+reveal: split
#+begin_src R :file figs/11_nhclst2.png :exports results :results graphics :tangle no
  cntr <- myPlot(cntr)
#+end_src
#+caption: Lloyd-Forgyのアルゴリズム (その2)
#+name: fig:11_nhclst2
#+attr_html: height 100%
#+attr_latex: :width 0.6\linewidth
[[file:figs/11_nhclst2.png]]

#+reveal: split
#+begin_src R :file figs/11_nhclst3.png :exports results :results graphics :tangle no
  cntr <- myPlot(cntr)
#+end_src
#+caption: Lloyd-Forgyのアルゴリズム (その3)
#+name: fig:11_nhclst3
#+attr_html: height 100%
#+attr_latex: :width 0.6\linewidth
[[file:figs/11_nhclst3.png]]

#+reveal: split
#+begin_src R :file figs/11_nhclst4.png :exports results :results graphics :tangle no
   cntr <- myPlot(cntr)
#+end_src
#+caption: Lloyd-Forgyのアルゴリズム (その4)
#+name: fig:11_nhclst4
#+attr_html: height 100%
#+attr_latex: :width 0.6\linewidth
[[file:figs/11_nhclst4.png]]

#+reveal: split
#+begin_src R :file figs/11_nhclst5.png :exports results :results graphics :tangle no
   cntr <- myPlot(cntr)
#+end_src
#+caption: Lloyd-Forgyのアルゴリズム (その5)
#+name: fig:11_nhclst5
#+attr_html: height 100%
#+attr_latex: :width 0.6\linewidth
[[file:figs/11_nhclst5.png]]

#+reveal: split
#+begin_src R :file figs/11_nhclst6.png :exports results :results graphics :tangle no
   cntr <- myPlot(cntr)
#+end_src
#+caption: Lloyd-Forgyのアルゴリズム (その6)
#+name: fig:11_nhclst6
#+attr_html: height 100%
#+attr_latex: :width 0.6\linewidth
[[file:figs/11_nhclst6.png]]

#+reveal: split
#+begin_src R :file figs/11_nhclst.png :exports results :results graphics :tangle no
   if(Sys.info()["sysname"]=="Darwin"){par(family="BIZUDGothic-Regular")}
   dsy <- daisy(rbind(om_subset[,jdx],cntr))
   clst <- apply(as.matrix(dsy)[1:n,(1:k)+n],
                 1,
                 function(x){which.min(x)})
   plot(predict(om_pca),
        col="blue", pch=19, cex=0.5,
        xaxt="n", yaxt="n", ann=FALSE)
   text(transform(predict(om_pca), PC2=PC2+0.5),
        labels=rownames(om_subset), col=clst, cex=1)
#+end_src
#+caption: クラスタリングの結果
#+name: fig:11_nhclst
#+attr_html: height 100%
#+attr_latex: :width 0.6\linewidth
[[file:figs/11_nhclst.png]]
 

* 実習
:PROPERTIES:
:reveal_background: #fef4f4
:END:
# 東京大学
** R : \(k\)-平均法
:PROPERTIES:
:ID:       BF14B712-D1D7-4CDA-BE9C-3BDCFDD7822F
:END:
- 関数 ~kmeans()~
  #+begin_src R :eval no :tangle no
    kmeans(x, centers, iter.max = 10, nstart = 1,
           algorithm = c("Hartigan-Wong", "Lloyd", "Forgy",
                         "MacQueen"), trace = FALSE)
    #' x: データフレーム
    #' centers: クラスタ数
    #' iter.max: 最大繰り返し数
    #' nstart: 初期値の候補数
    #' algorithm: 最適化法の指定．既定値は 'Hartigan-Wong'
  #+end_src
  - 結果は変数のスケールにも依存
    - 例えば測定値の単位により異なる
    - 必要ならば主成分分析の場合と同様にデータの標準化を行う

** R : 2次元でのクラスタ表示
:PROPERTIES:
:reveal_background: #fef4f4
:END:
- 関数 ~ggfortify::autoplot()~ (ggplot 系)
  #+begin_src R :eval no :tangle no
    autoplot(object, data = NULL, colour = "cluster", ...)
    #' object: stats::kmeans(), cluster::pam() などの返値
    #' data: クラスタリングに用いたデータ (kmeansの場合に必要)
    #' 詳細は '?ggfortify::autoplot.kmeans()' を参照
  #+end_src
- 関数 ~cluster::clusplot()~ を利用することもできる
      
** 練習問題
:PROPERTIES:
:reveal_background: #fef4f4
:ID:       F4543112-3BC2-4689-8887-5510E8A66EE1
:END:
- データセット ~japan_social.csv~ を用いて
  以下を確認しなさい
  #+begin_src R :eval no :tangle no
    js_df <- read_csv("data/japan_social.csv") |>
      column_to_rownames(var = "Pref") |> # 'Pref'を行名に変換
      select(-Area) # 地方名は除く
  #+end_src
  - 関数 ~kmeans()~ を用いて
    各変数平均0，分散1に標準化
    (関数 ~scale()~ を利用)
    したデータを7クラスタに分割しなさい
  - 各クラスタ内の県名を表示しなさい
  - 2次元散布図に各クラスタを表示しなさい
- データセット ~omusubi.csv~ でも確認しなさい
** COMMENT 解答例
#+begin_src R :exports none
  #' ---------------------------------------------------------------------------
  #' @practice 関数 kmeans による非階層的クラスタリング
#+end_src
#+begin_src R :eval no :exports none
  #' データの読み込み (japan_social.csv)
  js_data <- read_csv("data/japan_social.csv") 
  js_df <- js_data |> # 距離計算用のデータフレーム
    column_to_rownames(var = "Pref") |> # 'Pref'を行名に変換
    select(-Area) # 地方名は除く
  #' k-平均法の実行: 
  set.seed(1234) # 必要に応じて初期値の乱数のシード値を指定する
  k <- 7 # 分割数を指定
  js_kmeans <- js_df |>
    scale() |> # 標準化(平均0 分散1)
    kmeans(centers = k, # クラスタ数
           nstart = 20) # 初期値を20回変更して試す
  #' 各クラスター内の県名を表示
  #' kmeansの返値 cluster の情報を利用する
  #' kmeans.object$cluster または kmeans.object[["cluster"]] を用いる
  for(i in 1:k) {
    cat("=== cluster",i,"===\n")
    which(js_kmeans[["cluster"]] == i) |> names() |> print()
  }
  #' 2次元でのクラスタ表示
  #' 前回の主成分分析を利用したクラスタの表示とほぼ同様な記述
  js_kmeans |>
    autoplot(data = scale(js_df), # kmeans の場合は元のデータの指定が必須
             ## (kmeansの返値は距離行列の情報しか持っておらず主成分の計算ができないため)
             frame = TRUE, # クラスタ毎に枠を付ける
             frame.type = "convex", # 凸包 "convex"・楕円 "norm,t" が指定できる
             label = TRUE, # ラベルを付加
             label.repel = TRUE, # 重なりを回避(ラベルが消える場合もあるので注意)
             label.size = 3, # ラベルの大きさ
             label.show.legend = FALSE) # 凡例の中のアルファベットを除く
  #' @notes
  #' 以下は cluster::clusplot() を用いる場合の例
  clusplot(x = js_df, 
           clus = js_kmeans$cluster, # クラスタ番号
           stand = TRUE, # データの標準化を行う
           lines = 0, labels = 3, # 表示の指定
           main = NULL, sub = NULL, cex = 0.8, # タイトルなどの調整
           col.p = rainbow(k)[js_kmeans$cluster], # 虹色で色付け
           col.clus = "orange", shade = FALSE)	 # クラスタ囲みの指定

  #' データの読み込み (omusubi.csv)
  om_data <- bind_cols( # 日本語表記・地方の情報を追加
    read_csv(file = "data/omusubi.csv"),
    read_csv(file = "data/prefecture.csv"))
  om_df <- om_data |>  # 距離計算用のデータフレーム
    select(ume:etc,jp) |>
    set_names(c("梅","鮭","昆布","鰹","明太子","鱈子","ツナ","その他","県名")) |>
    column_to_rownames(var = "県名")
  #' 日本語表示のための設定
  if(Sys.info()["sysname"] == "Darwin") { # MacOSか調べて日本語フォントを指定
    jp_font <- "HiraMaruProN-W4"
    theme_update(text = element_text(family = jp_font))
    par(family = jp_font)
  } else {
    jp_font <- NULL # MacOSでない場合はフォントを指定しない
  }
  #' k-平均法の実行: 
  k <- 6 # 6分割で分析
  om_kmeans <- om_df |>
    sqrt() |> # Hellinger距離
    kmeans(centers = k, # クラスタ数
           nstart = 20) # 初期値を20回変更して試す
  #' 各クラスター内の県名を表示
  for(i in 1:k) {
    cat("=== cluster",i,"===\n")
    which(om_kmeans[["cluster"]] == i) |> names() |> print()
  }
  #' 2次元でのクラスタ表示
  om_kmeans |>
    autoplot(data = sqrt(om_df), 
             frame = TRUE, 
             frame.type = "norm", # 楕円で囲む
             label = TRUE, 
             label.repel = TRUE, 
             label.size = 3, 
             label.family = jp_font, # 日本語フォントの指定 (不要な場合は削除)
             label.show.legend = FALSE) 
  #' cluster::clusplot() による表示
  clusplot(x = sqrt(om_df), 
           clus = om_kmeans$cluster, # クラスタ番号
           stand = FALSE, # データは標準化しない
           lines = 0, labels = 3, # 表示の指定
           main = NULL, sub = NULL, cex = 0.8, # タイトルなどの調整
           col.p = rainbow(k)[om_kmeans$cluster], # 虹色で色付け
           col.clus = "orange", shade = FALSE)	 # クラスタ囲みの指定
#+end_src
#+begin_src R :exports none
  #' ---------------------------------------------------------------------------
#+end_src

** R : \(k\)-メドイド法 
:PROPERTIES:
:ID:       23F6D185-357C-4973-95B4-184D0335F0BC
:END:
- 関数 ~cluster::pam()~
  #+begin_src R :eval no :tangle no
    pam(x, k, diss = inherits(x, "dist"),
        metric = c("euclidean", "manhattan"), 
        medoids = if(is.numeric(nstart)) "random",
        nstart = if(variant == "faster") 1 else NA,
        stand = FALSE, cluster.only = FALSE,
        do.swap = TRUE,
        keep.diss = !diss && !cluster.only && n < 100,
        keep.data = !diss && !cluster.only,
        variant = c("original", "o_1", "o_2", "f_3", "f_4", "f_5", "faster"),
        pamonce = FALSE, trace.lev = 0)
    #' x: データフレーム，または距離行列 
    #' k: クラスタの数
    #' metric: 距離の指定(xがデータフレームの場合)
    #' stand: 標準化(平均0，絶対偏差1)
  #+end_src

** COMMENT 演習: 非階層的クラスタリング
:PROPERTIES:
:reveal_background: #EEEEFF
:END:
- [[./code/12-kmeans.r][12-kmeans.r]] を確認してみよう

** 練習問題
:PROPERTIES:
:reveal_background: #fef4f4
:ID:       95C3E2F9-62C2-48DA-A6D2-F3315F356388
:END:
- データセット ~japan_social.csv~ を用いて
  以下を確認しなさい
  - 関数 ~pam()~ を用いて
    各変数平均0，絶対偏差1に標準化したデータを7クラスタに分割しなさい
  - 各クラスタ内の県名を表示しなさい
  - 2次元散布図に各クラスタを表示しなさい
- データセット ~omusubi.csv~ でも確認しなさい
** COMMENT 解答例
#+begin_src R :exports none
  #' ---------------------------------------------------------------------------
  #' @practice 関数 pam による非階層的クラスタリング
#+end_src
#+begin_src R :eval no :exports none
  #' k-medoids の実行
  k <- 7
  js_pam <- js_df |>  
    pam(stand = TRUE, # 正規化(平均0 絶対偏差1)
        k = k) # クラスタ数の指定
  #' 各クラスター内の県名を表示
  for(i in 1:k){
    cat("=== cluster",i,"===\n")
    which(js_pam[["clustering"]] == i) |> names() |> print()
  }
  #' 2次元でのクラスタ表示
  js_pam |> 
    autoplot(frame = TRUE, 
             frame.type = "convex", 
             label = TRUE, 
             label.repel = TRUE, 
             label.size = 3, 
             label.show.legend = FALSE)
  #' Manhattan距離だとどのようになるか試してみる
  #' いくつかのクラスタでメンバが変わっている
  js_df |>  
    pam(stand = TRUE, 
        metric = "manhattan",
        k = k) |>
    autoplot(frame = TRUE, 
             frame.type = "convex", 
             label = TRUE, 
             label.repel = TRUE, 
             label.size = 3, 
             label.show.legend = FALSE) 
  #' cluster::clusplot() を用いる場合は kmeans とほぼ同様
  clusplot(x = js_df,
           clus = js_pam$clustering,
           stand = TRUE,
           lines = 0, labels = 3, 
           main = NULL, sub = NULL, cex = 0.8,
           col.p = rainbow(k)[js_pam$clustering],
           col.clus = "orange", shade = FALSE)

  #' k-medoids の実行
  k <- 6
  om_pam <- om_df |>
    sqrt() |>
    pam(k = k)
  #' 各クラスター内の県名を表示
  for(i in 1:k){
    cat("=== cluster",i,"===\n")
    which(om_pam[["clustering"]] == i) |> names() |> print()
  }
  #' 2次元でのクラスタ表示
  om_pam |> 
    autoplot(frame = TRUE, 
             frame.type = "convex", 
             label = TRUE, 
             label.repel = TRUE, 
             label.size = 3, 
             label.family = jp_font, 
             label.show.legend = FALSE)
  #' cluster::clusplot() による表示
  #' クラスタリングの結果は om_pam$clustering に保管されている
  clusplot(x = sqrt(om_df),
           clus = om_pam$clustering,
           stand = TRUE,
           lines = 0, labels = 3, 
           main = NULL, sub = NULL, cex = 0.8,
           col.p = rainbow(k)[om_pam$clustering],
           col.clus = "orange", shade = FALSE)
#+end_src
#+begin_src R :exports none
  #' ---------------------------------------------------------------------------
#+end_src


* COMMENT 解析事例
# 早稲田大学
** 都道府県別の社会生活統計指標
:PROPERTIES:
:ID:       4724A63D-8650-4583-8996-DD8E06C7BA77
:END:
- データの属性
  #+begin_example
  Forest : 森林面積割合 (%) 2014年
  Agri   : 就業者１人当たり農業産出額(販売農家）(万円) 2014年
  Ratio  : 全国総人口に占める人口割合 (%) 2015年
  Land   : 土地生産性（耕地面積１ヘクタール当たり）(万円) 2014年
  Goods  : 商業年間商品販売額［卸売業＋小売業］（事業所当たり）(百万円) 2013年
  #+end_example
- 平均0，分散1に正規化して解析

#+reveal: split
- ユークリッド距離 + k-平均法 
  #+begin_src R :exports none
    ### 総務省統計局の統計データによる例
    library(cluster)
    library(RColorBrewer)
    js_data <- bind_cols(
      read_csv(file="data/japan_social.csv"),
      read_csv(file="data/prefecture.csv"))

    ## k-平均法の実行: 
    set.seed(1234)
    k <- 7 # 分割数を指定
    js_km <- js_data |>
      select(Pref,Forest:Goods) |>
      column_to_rownames(var = "Pref") |>
      scale() |>
      kmeans(centers=k, nstart=20)
  #+end_src
  #+begin_src R :exports results
    ## 結果の確認 (各クラスター内の県名を表示)
    for(i in 1:k){
           cat("=== cluster",i,"===\n")
           print(js_data[["jp"]][js_km$cluster==i])
    }
  #+end_src
  
#+reveal: split
#+begin_src R :file figs/11_jskmeans.png :exports results :results graphics
  js_km |>
    autoplot(data = js_data,
             frame = TRUE,
             frame.type = "convex",
             label = TRUE,
             label.repel = TRUE,
             label.show.legend = FALSE)
#+end_src
#+caption: ユークリッド距離 + k-平均法 
#+name: fig:11_jskmeans
#+attr_html: height 100%
#+attr_latex: :width 0.6\linewidth
[[file:figs/11_jskmeans.png]]

#+reveal: split
- ユークリッド距離 + k-メドイド法 
  #+begin_src R :exports results :tangle yes
    ## k-medoids の実行
    js_pam <- js_data |>
      select(Pref,Forest:Goods) |>
      column_to_rownames(var = "Pref") |>
      scale() |>
      pam(k=k)
    ## metric="manhattan", stand=TRUE)
  #+end_src
  #+begin_src R :exports results
    ## 結果の確認 (各クラスター内の県名を表示)
    for(i in 1:k){
           cat("=== cluster",i,"===\n")
           print(js_data[["jp"]][js_pam$clustering==i])
    }
  #+end_src

#+reveal: split
#+begin_src R :file figs/11_jspam.png :exports results :results graphics
  js_pam |>
    autoplot(# data = js_data,
             frame = TRUE,
             frame.type = "convex",
             label = TRUE,
             label.repel = TRUE,
             label.show.legend = FALSE)
#+end_src
#+caption: ユークリッド距離 + k-メドイド法 
#+name: fig:11_jspam
#+attr_html: height 100%
#+attr_latex: :width 0.6\linewidth
[[file:figs/11_jspam.png]]

** 都道府県別好きなおむすびの具
:PROPERTIES:
:ID:       0EB616B0-E044-4E30-BB4C-602C3A1C135F
:END:
- データの属性
  #+begin_example
  Q2. おむすびの具では何が一番好きですか？
     A.梅 B.鮭 C.昆布 D.かつお E.明太子 F.たらこ Ｇ.ツナ H.その他
  【回答者数】
   男性	9,702人	    32.0%
   女性    20,616人	    68.0%
   総数    30,318人	   100.0%
  #+end_example
  - 回答を県別に集計
- Hellinger距離を利用
  #+begin_quote
  \(\boldsymbol{p},\boldsymbol{q}\)
  を確率ベクトルとして
  定義される確率分布の距離
  \begin{equation}
    d_{\mathrm{hel}}(\boldsymbol{p},\boldsymbol{q})
    =
    \frac{1}{\sqrt{2}}d_{\mathrm{euc}}(\sqrt{\boldsymbol{p}},\sqrt{\boldsymbol{q}})
  \end{equation}
  #+end_quote

#+reveal: split
- Hellinger距離 + k-メドイド法
  #+begin_src R :exports none
    #' データの読み込み("omusubi.csv"を用いる)
    om_data <- bind_cols(
      read_csv(file="data/omusubi.csv"),
      read_csv(file="data/prefecture.csv"))
    #' k-medoids の実行
    k <- 6
    om_pam <- om_data |>
      select(ume:etc,jp) |>
      column_to_rownames(var = "jp") |>
      sqrt() |> # Hellinger dist. daisy() |> 
      pam(k = k) # stand=TRUE は不要
  #+end_src
  #+begin_src R :exports results
    ## 結果の確認 (各クラスター内の県名を表示)
    for(i in 1:k){
      cat("=== cluster",i,"===\n")
      print(names(which(om_pam$clustering==i)))
    }
  #+end_src

#+reveal: split
#+begin_src R :file figs/11_ompam.png :exports results :results graphics
  om_pam |>
    autoplot(# data = om_data,
             frame = TRUE,
             frame.type = "convex",
             label = TRUE,
             label.repel = TRUE,
             label.family = "BIZUDGothic-Regular",
             label.show.legend = FALSE)
#+end_src

#+caption: Hellinger距離 + k-メドイド法 
#+name: fig:11_ompam
#+attr_html: height 100%
#+attr_latex: :width 0.6\linewidth
[[file:figs/11_ompam.png]]
   

* クラスタ構造の評価
** 階層的方法の評価
- 評価の対象
  - データ \(\boldsymbol{x}_i\) と最初に統合されたクラスタ \(C\) の距離
    #+begin_quote
    \begin{equation}
      d_i
      =
      D({\boldsymbol{x}_i},C)
    \end{equation}
    #+end_quote
  - 最後に統合された2つのクラスタ \(C',C''\) の距離
    #+begin_quote
    \begin{equation}
      D
      =
      D(C',C'')
    \end{equation}
    #+end_quote
- *凝集係数* (agglomerative coefficient)
  #+begin_quote
  \begin{equation}
    AC
    =
    \frac{1}{n}\sum_{i=1}^{n}\left(1-\frac{d_i}{D}\right)
  \end{equation}
  #+end_quote

** 凝集係数の性質
- 定義より
  #+begin_quote
  \begin{equation}
    0\le AC\le 1
  \end{equation}
  #+end_quote
  - 1に近いほどクラスタ構造が明瞭
- banner plot: 各 \((1-{d_i}/{D})\) を並べた棒グラフ
- banner plot の面積比として視覚化 

** 非階層的方法の評価
- 評価の対象
  - \(\boldsymbol{x}_i\) を含むクラスタ \(C^1\) と \(\boldsymbol{x}_i\) の距離
    #+begin_quote
    \begin{equation}
      d^1_i=D({\boldsymbol{x}_i},C^1\setminus{\boldsymbol{x}_i})
    \end{equation}
    #+end_quote
  - 一番近いクラスタ \(C^2\) と \(\boldsymbol{x}_i\) の距離
    #+begin_quote
    \begin{equation}
      d^2_i=D({\boldsymbol{x}_i},C^2)
    \end{equation}
    #+end_quote
- *シルエット係数* (silhouette coefficient)
  #+begin_quote
  \begin{equation}
    S_i
    =
    \frac{d^2_i-d^1_i}{\max(d^1_i,d^2_i)}
  \end{equation}
  #+end_quote

  # #   - データ \(\boldsymbol{x}_i\) が含まれているクラスタ: \(C^1\)
  # #   - \(C^1\) 以外で \(\boldsymbol{x}_i\) に一番近いクラスタ: \(C^2\)
  # # - \(\boldsymbol{x}_i\) を除いたクラスタ \(C^1\) とデータ \(\boldsymbol{x}_i\) の距離:
  # #   # #+begin_export latex
  # #   \begin{equation}
  # #	 d^1_i
  # #	 =
  # #	 D({\boldsymbol{x}_i},C^1\setminus{\boldsymbol{x}_i})
  # #   \end{equation}
  # #   # #+end_export
  # # - \(C^2\) と \(\boldsymbol{x}_i\) の距離:
  # #   # #+begin_export latex
  # #   \begin{equation}
  # #	 d^2_i
  # #	 =
  # #	 D({\boldsymbol{x}_i},C^2)
  # #   \end{equation}
  # #   # #+end_export

** シルエット係数の性質
- 定義より
  #+begin_quote
  \begin{equation}
    -1\le S_i\le 1
  \end{equation}
  #+end_quote
  - 1に近いほど適切なクラスタリング
- 全体の良さを評価するには \(S_i\) の平均を用いる
- 距離の計算を適切に行えば階層的方法でも利用可


* COMMENT 演習
:PROPERTIES:
:reveal_background: #fef4f4
:END:
# 早稲田大学
** 問題
:PROPERTIES:
:reveal_background: #fef4f4
:END:
- 以下の問に答えなさい
  - 群平均法において凝集係数が以下を満たすことを示しなさい
    #+begin_quote
    \begin{equation}
      0\le AC\le 1
    \end{equation}
    #+end_quote
  - シルエット係数が以下を満たすことを示しなさい
    #+begin_quote
    \begin{equation}
      -1\le S_i\le 1
    \end{equation}
    #+end_quote

** 解答例
:PROPERTIES:
:reveal_background: #fef4f4
:END:
- 2つのクラスタ\(C_{a},C_{b}\)が最も近いとする
  #+begin_quote
  \begin{equation}
       D(C_{c},C_{d})\ge D(C_{a},C_{b}),
       \quad\forall c,d
  \end{equation}
  #+end_quote

#+reveal: split
- 統合して計算される距離では下が成立
  #+begin_quote
  \begin{align}
       D(C_{a}+C_{b}, C_{c})
       &=
         \frac{|C_{a}|D(C_{a},C_{c})+|C_{b}|D(C_{b},C_{c})}{|C_{a}|+|C_{b}|}\\
       &\ge
         \frac{|C_{a}|D(C_{a},C_{b})+|C_{b}|D(C_{a},C_{b})}{|C_{a}|+|C_{b}|}\\
       &=D(C_{a},C_{b})
  \end{align}
  統合した結果，それより短い距離が現れることはない
  #+end_quote

#+reveal: split
- 以上より
  #+begin_quote
  \begin{equation}
       0\le d_{i}\le D
  \end{equation}
  \begin{equation}
       0\le 1-\frac{d_i}{D}\le 1
  \end{equation}
  よって
  \begin{equation}
       0\le AC\le 1
  \end{equation}
  #+end_quote

#+reveal: split
- 非負値の大小関係に注意する
  #+begin_quote
  \begin{equation}
       -\max(d^{1}_{i},d^{2}_{i})\le d^{2}_{i}-d^{1}_{i}\le\max(d^{1}_{i},d^{2}_{i})
  \end{equation}
  より
  \begin{equation}
       -1\le S_i\le 1
  \end{equation}
  #+end_quote
  

* 実習
:PROPERTIES:
:reveal_background: #fef4f4
:END:
# 東京大学
** R : 凝集係数
:PROPERTIES:
:ID:       5EFEBBAA-7795-4ED3-9A25-C5506764F4B9
:END:
- 関数 ~cluster::agnes()~ の返値の情報
  #+begin_src R :eval no :tangle no
    object[["ac"]] # 凝集係数の取得 (object$ac でも良い)
    object[["height"]] # デンドログラムの高さ(結合時のクラスタ距離)
    object[["order.lab"]] # デンドログラムの並び順のラベル
    #' object: cluster::agnes() の返値
  #+end_src
  - これらを利用して banner plot を描くことができる
  - 関数 ~summary(object)~ はこれらの情報をまとめて表示する
#+reveal: split
- 視覚化のための関数 (graphics 系)
  #+begin_src R :eval no :tangle no
    #' cluster::plot.agnes() 系統樹および凝集係数の表示
    plot(x, ask = FALSE, which.plots = NULL, main = NULL,
         sub = paste("Agglomerative Coefficient = ",round(x$ac, digits = 2)),
         adj = 0, nmax.lab = 35, max.strlen = 5, xax.pretty = TRUE, ...)
    #' x: cluster::agnes() の返値
    #' which.plots: 1 (banner plot), 2 (dendrogram)
    #' banner plot の表示には以下の cluster::bannerplot() が呼出される
    bannerplot(x, w = rev(x$height), fromLeft = TRUE,
               main=NULL, sub=NULL, xlab = "Height",  adj = 0,
               col = c(2, 0), border = 0, axes = TRUE, frame.plot = axes,
               rev.xax = !fromLeft, xax.pretty = TRUE,
               labels = NULL, nmax.lab = 35, max.strlen = 5,
               yax.do = axes && length(x$order) <= nmax.lab,
               yaxRight = fromLeft, y.mar = 2.4 + max.strlen/2.5, ...)
  #+end_src

** 練習問題
:PROPERTIES:
:reveal_background: #fef4f4
:ID:       EAEFCCDA-22C8-40F1-8F9A-462C6E2AD824
:END:
- データセット ~japan_social.csv~ を用いて
  以下を検討しなさい
  - 関数 ~agnes()~ を用いて階層的クラスタリングを行いなさい
    - 標準化: 行う
    - データ距離: ユークリッド距離，およびマンハッタン距離
    - クラスタ距離: 群平均法
  - 凝集係数を用いて2つのデータ距離の評価を行いなさい
  - 凝集係数が低いいくつかのデータを削除して評価しなさい
** COMMENT 解答例
#+begin_src R :exports none
  #' ---------------------------------------------------------------------------
  #' @practice 凝集係数による距離の検討
#+end_src
#+begin_src R :eval no :exports none
  #' ユークリッド距離による階層的クラスタリング
  js_agnes_euc <- agnes(js_df,
                        metric="euclidean", # データ距離
                        stand=TRUE,	    # 標準化
                        method="average")   # クラスタ距離
  js_agnes_euc |> as.dendrogram() |>  
    ggdendrogram(rotate = FALSE, 
                 theme_dendro = FALSE) + 
    labs(title = "Euclidean distance",
         x = "Prefecture", y = "Height") +
    theme(axis.text.y = element_text(size = 9))
  #' マンハッタン距離による階層的クラスタリング
  js_agnes_man <- agnes(js_df,
                        metric="manhattan",
                        stand=TRUE,
                        method="average")
  js_agnes_man |> as.dendrogram() |>  
    ggdendrogram(rotate = FALSE, 
                 theme_dendro = FALSE) + 
    labs(title = "Manhattan distance",
         x = "Prefecture", y = "Height") +
    theme(axis.text.y = element_text(size = 9))

  #' 凝集係数の確認
  js_agnes_euc[["ac"]]
  js_agnes_man[["ac"]]
  #' ユークリッド距離の方がわずかに良いことがわかる

  #' データ毎の凝集係数の表示
  tibble(x = js_agnes_euc[["height"]],
         y = length(js_agnes_euc[["height"]]):1) |>
    ggplot() +
    #' 各枝のheightと最大値で矩形を描く
    geom_rect(aes(xmin = x, xmax = max(x),
                  ymin = y, ymax = y+1), 
              fill = "orange", alpha = 0.6) + # 塗り潰し色と透明度を指定
    #' y軸にラベルを表示する
    scale_y_continuous(breaks = length(js_agnes_euc[["order.lab"]]):1,
                       expand = expansion(add = 0.5),
                       labels = js_agnes_euc[["order.lab"]]) +
    labs(title = "Euclidean distance") +
    theme(axis.text.y = element_text(size = 9))
  tibble(x = js_agnes_man[["height"]],
         y = length(js_agnes_man[["height"]]):1) |>
    ggplot() +
    geom_rect(aes(xmin = x, xmax = max(x),
                  ymin = y, ymax = y+1), 
              fill = "orange", alpha = 0.6) + 
    scale_y_continuous(breaks = length(js_agnes_man[["order.lab"]]):1,
                       expand = expansion(add = 0.5),
                       labels = js_agnes_man[["order.lab"]]) +
    labs(title = "Manhattan distance") +
    theme(axis.text.y = element_text(size = 9))

  #' @notes
  #' bannerplot の情報を整理するための関数を定義してもよい
  my_bannerplot <- function(object, # agnesの返値
                            fill = "orange", alpha = 0.6, ...) {
    p <- tibble(x = object[["height"]],
                y = length(object[["height"]]):1) |>
      ggplot() +
      geom_rect(aes(xmin = x, xmax = max(x),
                    ymin = y, ymax = y+1), 
                fill = fill, alpha = alpha) + 
      scale_y_continuous(breaks = length(object[["order.lab"]]):1,
                         expand = expansion(add = 0.5),
                         labels = object[["order.lab"]])
    p
  }
  my_bannerplot(js_agnes_euc,
               fill = "red", alpha = 0.6)

  #' 一部のデータの距離が大きいと凝集係数は大きくなりがち (理由を考えてみよう)
  #' 北海道，東京，宮崎，鹿児島を除いて再計算する 
  #' 返値の要素を抽出する場合にはパイプ(|>)が使えない場合があるので注意
  agnes(js_df |> slice(-c(1,13,45,46)),
        metric = "euclidean",
        stand = TRUE,
        method = "average")[["ac"]]
  agnes(js_df |> slice(-c(1,13,45,46)),
        metric = "manhattan",
        stand = TRUE,
        method = "average")[["ac"]]
  #' いずれにせよユークリッド距離の方が凝集係数は大きいことがわかる
  #' 個別の係数の確認
  js_df |> slice(-c(1,13,45,46)) |>
    agnes(metric = "euclidean",
          stand = TRUE,
          method = "average") |>
    my_bannerplot() + # @notes で定義した関数を利用
    labs(title = "Euclidean distance") +
    theme(axis.text.y = element_text(size = 9))
  js_df |> slice(-c(1,13,45,46)) |>
    agnes(metric = "manhattan",
          stand = TRUE,
          method = "average") |>
    my_bannerplot() +
    labs(title = "Manhattan distance") +
    theme(axis.text.y = element_text(size = 9))

  #' @notes
  #' graphics系の関数を利用する場合は以下のようにすればよい
  #' デンドログラムの表示
  plot(js_agnes_euc, which.plots=2, 
       main="euclidean") 
  plot(js_agnes_man, which.plots=2, 
       main="manhattan") 
  #' データ毎の凝集係数の表示
  plot(js_agnes_euc, which.plots=1, # banner plotの表示
       nmax.lab=50,   # 表示するラベルの上限 (標準は40)
       max.strlen=5,  # 表示するラベルの文字数の上限
       main="euclidean")
  plot(js_agnes_man, which.plots=1,
       nmax.lab=50,  
       max.strlen=5,
       main="manhattan")
#+end_src
#+begin_src R :exports none
  #' ---------------------------------------------------------------------------
#+end_src
# #+begin_src R :exports none
#   tibble(x = js_agnes_euc[["height"]],
#          ymin = fct_rev(as_factor(js_agnes_euc[["order.lab"]]))[-1],
#          ymax = fct_rev(as_factor(js_agnes_euc[["order.lab"]]))[-47]) |>
#     ggplot() +
#     geom_rect(aes(xmin = x, xmax = max(x),
#                   ymin = ymin, ymax = ymax), 
#               fill = "orange", alpha = 0.6) + # 塗り潰し色と透明度を指定
#     labs(title = "Euclidean distance") +
#     theme(axis.text.y = element_text(size = 9))
#   tibble(x = js_agnes_man[["height"]],
#          ymin = fct_rev(as_factor(js_agnes_man[["order.lab"]]))[-1],
#          ymax = fct_rev(as_factor(js_agnes_man[["order.lab"]]))[-47]) |>
#     ggplot() +
#     geom_rect(aes(xmin = x, xmax = max(x),
#                   ymin = ymin, ymax = ymax), 
#               fill = "orange", alpha = 0.6) + # 塗り潰し色と透明度を指定
#     labs(title = "Manhattan distance") +
#     theme(axis.text.y = element_text(size = 9))
#   extract_banner <- function(x) {
#     labels <- x$order.lab
#     tibble(x = x$height,
#            ymin = fct_rev(as_factor(labels))[-1],
#            ymax = fct_rev(as_factor(labels))[-length(labels)])
#   }
#   extract_banner(js_agnes_euc) |>
#     ggplot() +
#     geom_rect(aes(xmin = x, xmax = max(x),
#                   ymin = ymin, ymax = ymax), 
#               fill = "red", alpha = 0.6)
# #+end_src

** R : シルエット係数
:PROPERTIES:
:ID:       6AF1B625-7D2F-40F4-9AC5-236684343A73
:END:
- 関数 ~cluster::pam()~ の返値の情報
  #+begin_src R :eval no :tangle no
    object[["silinfo"]] # シルエット係数に関する様々な情報
    object[["silinfo"]][["widths"]] # 各データのシルエット係数
    object[["silinfo"]][["clus.avg.widths"]] # 各クラスタのシルエット係数の平均
    object[["silinfo"]][["avg.width"]] # シルエット係数の平均
    #' object: cluster::agnes() の返値
  #+end_src
  - 関数 ~summary(object)~ はこれらの情報をまとめて表示する
- 補助的な関数
  #+begin_src R :eval no :tangle no
    #' シルエット係数の取得
    silhouette(x, ...)
    #' x: cluster::pam() などの返値
    silhouette(x, dist, dmatrix, ...)
    #' x: stats::cutree() などの返値
    #' dist/dmatrix: 距離行列または解離度を表す行列など
  #+end_src
#+reveal: split
- 視覚化のための関数 (ggplot 系)
  #+begin_src R :eval no :tangle no
    #' ggfortify::autoplot.silhouette() シルエット係数の表示
    autoplot(object,
      colour = "red", linetype = "dashed", size = 0.5, bar.width = 1, ...)
    #' object: cluster::silhouette() の返値
    #' colour/linetype/size: reference line の設定
  #+end_src
#+reveal: split
- 視覚化のための関数 (graphics 系)
  #+begin_src R :eval no :tangle no
    #' cluster::plot.partition() 2次元クラスタおよびシルエット係数の表示
    plot(x, ask = FALSE, which.plots = NULL,
         nmax.lab = 40, max.strlen = 5, data = x$data, dist = NULL,
         stand = FALSE, lines = 2,
         shade = FALSE, color = FALSE, labels = 0, plotchar = TRUE,
         span = TRUE, xlim = NULL, ylim = NULL, main = NULL, ...)
    #' x: cluster::pam() などの返値
    #' which.plots: 1 (cluster plot), 2 (silhouette plot)
    #' silhouette plot の表示には以下の cluster::plot.silhouette() が呼出される
    plot(x, nmax.lab = 40, max.strlen = 5,
         main = NULL, sub = NULL, xlab = expression("Silhouette width "* s[i]),
         col = "gray",  do.col.sort = length(col) > 1, border = 0,
         cex.names = par("cex.axis"), do.n.k = TRUE, do.clus.stat = TRUE, ...)
    #' x: cluster::silhouette() の返値
  #+end_src

** COMMENT 演習: クラスタ分析の評価
:PROPERTIES:
:reveal_background: #EEEEFF
:END:
- [[./code/12-eval.r][12-eval.r]] を確認してみよう

** 練習問題
:PROPERTIES:
:reveal_background: #fef4f4
:ID:       AA8EF433-1EEC-4705-BFB1-EE300889D6F1
:END:
- データセット ~omusubi.csv~ を用いて
  以下を検討しなさい
  - Hellinger距離を用いて距離行列を計算しなさい
    #+begin_quote
    \(\boldsymbol{p},\boldsymbol{q}\)
    を確率ベクトルとして
    定義される確率分布の距離
    \begin{equation}
      d_{\mathrm{hel}}(\boldsymbol{p},\boldsymbol{q})
      =
      \frac{1}{\sqrt{2}}d_{\mathrm{euc}}(\sqrt{\boldsymbol{p}},\sqrt{\boldsymbol{q}})
    \end{equation}
    #+end_quote
  - クラスタ数4-10のシルエット係数を比較しなさい
  - 適当と思われるクラスタ数による分析を行いなさい
  - Euclid距離を用いて同様な分析を行いなさい
** COMMENT 解答例
#+begin_src R :exports none
  #' ---------------------------------------------------------------------------
  #' @practice シルエット係数によるクラスタ数の検討
#+end_src
#+begin_src R :eval no :exports none
  #' クラスタ数 4-10 で平均シルエット係数を確認
  om_df_hel <- om_df |> sqrt() # Hellinger距離を計算しやすくデータフレームを用意
  for(k in 4:10){
    cat(pam(om_df_hel, k = k)$silinfo$avg.width,
        " (k = ", k, ")\n", sep="")
  }
  #' pam(om_df_hel, k = k)[["silinfo"]][["avg.width"]] と書いても良い
  #' k=7,8,9 (上位3つ) のシルエット係数を視覚化
  for(k in 7:9) {
    p <- pam(om_df_hel, k = k) |>
      silhouette() |>
      autoplot() +
      labs(title = paste("k =", k))
    print(p) # ggplotはfor文内では明示的にprintする必要がある
  }

  #' 悪いシルエット係数が少ないという意味で k=8 が良さそう
  k <- 8
  om_df_hel |>
    pam(k = k) |>
    autoplot(frame = TRUE, 
             frame.type = "convex", 
             label = TRUE, 
             label.repel = TRUE, 
             label.size = 3, 
             label.family = jp_font, 
             label.show.legend = FALSE)
  #' 同様な描画は以下でも可能
  om_pam <- om_df_hel |>
    pam(k = k)
  plot(om_pam,
       which.plot = 1, # cluster::clusplot のオプションを参考
       stand = TRUE,
       lines = 0, labels = 3, 
       main = "", sub = NULL, cex = 0.8, # タイトルと文字の大きさの調整
       col.p = rainbow(k)[om_pam$clustering], # クラスタ番号ごとに色付け
       col.clus = "orange", shade = FALSE) # クラスタを楕円で表示

  #' Euclid距離による分析
  #' k = 5-10 で検証
  for(k in 5:10) {
    foo <- pam(om_df, k = k)
    p <- foo |>
      silhouette() |>
      autoplot() +
      labs(title = paste("k =", k, "(Silhouette coef. =",
                         round(foo$silinfo$avg.width, digits = 3), ")"))
    print(p) 
  }
  #' 悪いシルエット係数が少ないという意味で k=7 が良さそう
  k <- 7
  om_df |>
    pam(k = k) |>
    autoplot(frame = TRUE, 
             frame.type = "norm", 
             label = TRUE, 
             label.repel = TRUE, 
             label.size = 3, 
             label.family = jp_font, 
             label.show.legend = FALSE)
#+end_src
#+begin_src R :eval no :exports none
  #' @notes
  #' 階層的クラスタリングでもシルエット係数を計算することができる
  om_agnes <- agnes(om_df_hel)
  om_agnes |> as.dendrogram() |>
    ggdendrogram()
  silhouette(cutree(om_agnes, k = k), 
             daisy(om_df_hel)) |> # 距離行列が必要
    autoplot()
  #' シルエット係数のグラフはクラスタ毎に降順(大きいものが上)に並べ替えられている
  #' グラフに合わせた要素名を取り出すには例えば以下のようにすれば良い
  silhouette(cutree(om_agnes, k = k), daisy(om_df_hel)) |>
    as_tibble() |>
    mutate(prefecture=rownames(om_df_hel)) |>
    arrange(desc(cluster), desc(sil_width))
#+end_src
#+begin_src R :exports none
  #' ---------------------------------------------------------------------------
#+end_src


* COMMENT 解析事例
# 早稲田大学
** 都道府県別の社会生活統計指標
:PROPERTIES:
:ID:       491B5831-261E-423F-BFCF-E6B0721A90B1
:END:
- 凝集係数を用いて階層的方法の距離を検討
- ユークリッド距離とマンハッタン距離を比較
  - 正規化は共通 (平均0，絶対偏差1)
  - クラスタ距離は群平均法
    
#+reveal: split
#+begin_src R :file figs/11_jsbannereuc.png :exports results :results graphics
  js_agnes_euc <- js_data |>
    select(Forest:Goods,jp) |>
    column_to_rownames(var = "jp") |>
    agnes(metric = "euclidean",
          stand = TRUE,
          method = "average")
  if(Sys.info()["sysname"]=="Darwin"){par(family="BIZUDGothic-Regular")}
  plot(js_agnes_euc, which.plots=1,
       sub = paste("凝集係数 = ",round(js_agnes_euc$ac, digits = 3)),
       nmax.lab=50, 
       max.strlen=5, 
       cex.axis=0.5,
       main="")
#+end_src
#+caption: 凝集係数 (ユークリッド距離)
#+name: fig:11_jsbannereuc
#+attr_html: height 100%
#+attr_latex: :width 0.6\linewidth
file:figs/11_jsbannereuc.png
  
#+reveal: split
#+begin_src R :file figs/11_jsdendroeuc.png :exports results :results graphics
  js_agnes_euc |>
    as.dendrogram() |>
    ggdendrogram(rotate = TRUE, theme_dendro = FALSE) +
    labs(title = "Euclid 距離 + 群平均法",
         x = "県名", y = "距離") +
    theme(axis.text.y = element_text(size = 9))
#+end_src
#+caption: デンドログラム (ユークリッド距離)
#+name: fig:11_jsdendroeuc
#+attr_html: height 100%
#+attr_latex: :width 0.6\linewidth
file:figs/11_jsdendroeuc.png

#+reveal: split
#+begin_src R :file figs/11_jsbannerman.png :exports results :results graphics
  js_agnes_man <- js_data |>
    select(Forest:Goods,jp) |>
    column_to_rownames(var = "jp") |>
    agnes(metric = "manhattan",
          stand = TRUE,
          method = "average")
  if(Sys.info()["sysname"]=="Darwin"){par(family="BIZUDGothic-Regular")}
  plot(js_agnes_man, which.plots=1,
       sub = paste("凝集係数 = ",round(js_agnes_man$ac, digits = 3)),
       nmax.lab=50, 
       max.strlen=5, 
       cex.axis=0.5,
       main="")
#+end_src
#+caption: 凝集係数 (マンハッタン距離)
#+name: fig:11_jsbannerman
#+attr_html: height 100%
#+attr_latex: :width 0.6\linewidth
file:figs/11_jsbannerman.png
  
#+reveal: split
#+begin_src R :file figs/11_jsdendroman.png :exports results :results graphics
  js_agnes_man |>
    as.dendrogram() |>
    ggdendrogram(rotate = TRUE, theme_dendro = FALSE) +
    labs(title = "Manhattan 距離 + 群平均法",
         x = "県名", y = "距離") +
    theme(axis.text.y = element_text(size = 9))
#+end_src
#+caption: デンドログラム (マンハッタン距離)
#+name: fig:11_jsdendroman
#+attr_html: height 100%
#+attr_latex: :width 0.6\linewidth
file:figs/11_jsdendroman.png

#+reveal: split
- 一部のデータの距離が大きいと凝集係数は大きくなりがち (理由を考えてみよう)
- 北海道，東京，宮崎，鹿児島を除いて再計算する 
  #+begin_src R :exports results
    cat("凝集係数 (ユークリッド距離)\n")
    (js_data |>
      select(Forest:Goods,jp) |>
      slice(-c(1,13,45,46)) |>
      column_to_rownames(var = "jp") |>
      agnes(metric = "euclidean",
            stand = TRUE,
            method = "average"))$ac |> round(digits = 3)
    cat("凝集係数 (マンハッタン距離)\n")
    (js_data |>
      select(Forest:Goods,jp) |>
      slice(-c(1,13,45,46)) |>
      column_to_rownames(var = "jp") |>
      agnes(metric = "manhattan",
            stand = TRUE,
            method = "average"))$ac |> round(digits = 3)
  #+end_src
     
** 都道府県別好きなおむすびの具
:PROPERTIES:
:ID:       930CC123-5CB9-4266-B82D-D0095A28DBF9
:END:
- シルエット係数を用いて非階層的方法のクラスタ数を検討
  - データ距離はHellinger距離
  - クラスタ距離は群平均法
- クラスタ数を4-10として比較
  #+begin_src R :exports results :tangle yes
    ## さまざまなクラスタ数で平均シルエット係数を確認
    om_data_hel <- om_data |>
      select(ume:etc,jp) |>
      column_to_rownames(var = "jp") |>
      sqrt() # Hellinger dist.用
    om_sil <- tibble(k = 4:10, sil = NULL)
    cat("シルエット係数\n")
    for(i in 1:nrow(om_sil)){
      k <- om_sil[i,][["k"]]
      om_sil[i,"sil"] <- round(pam(om_data_hel, k = k)$silinfo$avg.width, digits = 3)
      cat(om_sil[i,][["sil"]], " (k = ",k,")\n", sep="")
    }
  #+end_src

#+reveal: split
#+begin_src R :file figs/11_omsil7.png :exports results :results graphics :height 700
  om_data_hel |>
    pam(k = 7) |>
    silhouette() |>
    autoplot() +
    labs(x = "都道府県(クラスタ)",
         y = "シルエット係数")
#+end_src
#+caption: シルエット係数の分布 (k=7)
#+name: fig:11_omsil7
#+attr_html: height 100%
#+attr_latex: :width 0.6\linewidth
file:figs/11_omsil7.png

#+reveal: split
#+begin_src R :file figs/11_omsil8.png :exports results :results graphics :height 700
  om_data_hel |>
    pam(k = 8) |>
    silhouette() |>
    autoplot() +
    labs(x = "都道府県(クラスタ)",
         y = "シルエット係数")
#+end_src
#+caption: シルエット係数の分布 (k=8)
#+name: fig:11_omsil8
#+attr_html: height 100%
#+attr_latex: :width 0.6\linewidth
file:figs/11_omsil8.png

#+reveal: split
#+begin_src R :file figs/11_omsil9.png :exports results :results graphics :height 700
  om_data_hel |>
    pam(k = 9) |>
    silhouette() |>
    autoplot() +
    labs(x = "都道府県(クラスタ)",
         y = "シルエット係数")
#+end_src
#+caption: シルエット係数の分布 (k=9)
#+name: fig:11_omsil9
#+attr_html: height 100%
#+attr_latex: :width 0.6\linewidth
file:figs/11_omsil9.png

#+reveal: split
#+begin_src R :file figs/11_omclusplot8.png :exports results :results graphics :height 700
  ## k=8が良さそう
  om_data_hel |>
    pam(k = 8) |>
    autoplot(# data = om_data,
             frame = TRUE,
             frame.type = "convex",
             label = TRUE,
             label.repel = TRUE,
             label.family = "BIZUDGothic-Regular",
             label.show.legend = FALSE)
#+end_src
#+caption: 非階層的クラスタリング (k=8)
#+name: fig:11_omclusplot8
#+attr_html: height 100%
#+attr_latex: :width 0.6\linewidth
[[file:figs/11_omclusplot8.png]]


* 次回の予定
- *第1回 : 時系列の基本モデル*
- 第2回 : モデルの推定と予測  


* Footnotes
* COMMENT ローカル変数
# Local Variables:
# org-latex-listings: minted
# End:
